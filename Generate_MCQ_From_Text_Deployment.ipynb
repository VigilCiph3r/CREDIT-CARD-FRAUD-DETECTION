{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "409c4bcfab3c4169bfc540626a458d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_179a4fd505aa4c909766ed1681de6d94",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ade86601398c40238f50a7128c28dc43",
              "IPY_MODEL_8a93af55ac6c425ca0b8f98e682bf961",
              "IPY_MODEL_5f0df84f40a84c7abb2992d7892e9a57"
            ]
          }
        },
        "179a4fd505aa4c909766ed1681de6d94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ade86601398c40238f50a7128c28dc43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9216012842d84e969149c9e043103062",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47c29eb53cb844569c7631d634144473"
          }
        },
        "8a93af55ac6c425ca0b8f98e682bf961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f859151451d9426ebbbe3f2ba20c588e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 483,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 483,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f74fd8a9bc445169b0d2f62510126c4"
          }
        },
        "5f0df84f40a84c7abb2992d7892e9a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0dddcf8a26384256affda11429852aa6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 483/483 [00:00&lt;00:00, 12.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5c81ad33fb64325a78913daba62350b"
          }
        },
        "9216012842d84e969149c9e043103062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47c29eb53cb844569c7631d634144473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f859151451d9426ebbbe3f2ba20c588e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f74fd8a9bc445169b0d2f62510126c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0dddcf8a26384256affda11429852aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5c81ad33fb64325a78913daba62350b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e574334a1fe402e9bfa65e5acf8b732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_88566740eaaf482488396705a2aa2301",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ecd595a153014b4eaaea0273eb55956a",
              "IPY_MODEL_6a838e75bbb14f6a9b3a175d2f7a7acc",
              "IPY_MODEL_e7ed74d2c8674b988640eb4e38b80bc5"
            ]
          }
        },
        "88566740eaaf482488396705a2aa2301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecd595a153014b4eaaea0273eb55956a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71b984d6e421432bb3d79d8e81ad16be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_493dcf7dabe842379bede9ab50d22e40"
          }
        },
        "6a838e75bbb14f6a9b3a175d2f7a7acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9049999b987b463099dbe0223d59ee69",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59974f7cd12648b0bef836ded25b4903"
          }
        },
        "e7ed74d2c8674b988640eb4e38b80bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2551058343c5474eb2a687b087ad7ef1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 256M/256M [00:05&lt;00:00, 45.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_981d95d8ca4c46deaa3534e5cd1abe38"
          }
        },
        "71b984d6e421432bb3d79d8e81ad16be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "493dcf7dabe842379bede9ab50d22e40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9049999b987b463099dbe0223d59ee69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59974f7cd12648b0bef836ded25b4903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2551058343c5474eb2a687b087ad7ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "981d95d8ca4c46deaa3534e5cd1abe38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acf38f4614584684b3f72c9417a73b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9403f33e6304297a4fcb929f8eb69c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bc4cf032724b4688abf274ff09cab87d",
              "IPY_MODEL_77464fd2574544fb95521b8c6a9e2b5e",
              "IPY_MODEL_41ac03a99b084fdf9dc083990b90caf7"
            ]
          }
        },
        "a9403f33e6304297a4fcb929f8eb69c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc4cf032724b4688abf274ff09cab87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d0464303f214b0c82a30f824cc2df2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6dd6a65dd1046f58dcaf6008da3eb9a"
          }
        },
        "77464fd2574544fb95521b8c6a9e2b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d0d4a6f78e114382a2368f9a08b70610",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_102d060a6e9d4bd6bc1b084eddd0b47a"
          }
        },
        "41ac03a99b084fdf9dc083990b90caf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0f00b89ed72456bb7c9fe68d7d0a989",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 784B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8170101e4d104d94872f58698c2895f7"
          }
        },
        "2d0464303f214b0c82a30f824cc2df2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6dd6a65dd1046f58dcaf6008da3eb9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0d4a6f78e114382a2368f9a08b70610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "102d060a6e9d4bd6bc1b084eddd0b47a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0f00b89ed72456bb7c9fe68d7d0a989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8170101e4d104d94872f58698c2895f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f045566a71de402b8c86a1a740e1b6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92f010bb4b6b4da5a8ee7b2f051360df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_461e97cb566d4e299f8d53ccbaa75ce2",
              "IPY_MODEL_272fef320d9044208d9758911477513e",
              "IPY_MODEL_cd20e7e38b284278bb7b9df8eb81642d"
            ]
          }
        },
        "92f010bb4b6b4da5a8ee7b2f051360df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "461e97cb566d4e299f8d53ccbaa75ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3619a268811434db81542d158a56361",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79c40009ef164be48e5b0df62de8f242"
          }
        },
        "272fef320d9044208d9758911477513e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e7606c758a8412db93b236faaa90470",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_235638708475445dae81299905ec280f"
          }
        },
        "cd20e7e38b284278bb7b9df8eb81642d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a717b7ade95f4da894829652611ed354",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 878kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57abad856f7948eaa37a3c0f1eda5a30"
          }
        },
        "a3619a268811434db81542d158a56361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79c40009ef164be48e5b0df62de8f242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e7606c758a8412db93b236faaa90470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "235638708475445dae81299905ec280f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a717b7ade95f4da894829652611ed354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57abad856f7948eaa37a3c0f1eda5a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b762aaf1ac7d43418413f7fe5eedcc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84d60e77aba643b98e3230bdd377673f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cb86e282268b427b881b1f8083c78403",
              "IPY_MODEL_33338fe80a7941c582760b5f6bef1c08",
              "IPY_MODEL_f9721f70a3c14fff98fadd428b92bf00"
            ]
          }
        },
        "84d60e77aba643b98e3230bdd377673f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb86e282268b427b881b1f8083c78403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78811c58b38d483983b9dc8feffe06db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d90621601f44009ad25e5614a6ba27a"
          }
        },
        "33338fe80a7941c582760b5f6bef1c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ef55071cb72c4510a45b9370ea6490e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6268f3c2d2664dc289db2e8e510e3546"
          }
        },
        "f9721f70a3c14fff98fadd428b92bf00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99742f4c78ba46c8831b4b05ee5c6830",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 969kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0feeaa116e0f469b8c1a12f7b436470b"
          }
        },
        "78811c58b38d483983b9dc8feffe06db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d90621601f44009ad25e5614a6ba27a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef55071cb72c4510a45b9370ea6490e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6268f3c2d2664dc289db2e8e510e3546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99742f4c78ba46c8831b4b05ee5c6830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0feeaa116e0f469b8c1a12f7b436470b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VigilCiph3r/CREDIT-CARD-FRAUD-DETECTION/blob/main/Generate_MCQ_From_Text_Deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Multiple Choice Questions from a Text"
      ],
      "metadata": {
        "id": "DmOja30Xuo6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PROBLEM STATEMENT\n",
        "Given a text phrase, we want to generate multiple choice questions (MCQ)s automatically from the text. The tool can be used by educators, teachers or by professionals to create assesments, evaluations, quizes surveys at scale."
      ],
      "metadata": {
        "id": "OKEco39mqRu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "MCQs have several advantages, including rapid evaluation, shorter testing time, uniform scoring, and the option of an electronic evaluation. Many examinations employ MCQ-based question papers administered in a computerised setting. Manually preparing MCQs, on the other hand, is time-consuming and costly. As a result, the research community expended much effort in developing approaches for the automatic creation of MCQs. We will explore one such method here using machine learning and natural language processing."
      ],
      "metadata": {
        "id": "9QXQvOdbhODf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use following text as an example\n",
        "# source: https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained\n",
        "text = \"\"\" Machine learning is behind chatbots and predictive text, language translation apps, the shows Netflix suggests to you, and how your social media feeds are presented. It powers autonomous vehicles and machines that can diagnose medical conditions based on images.\n",
        "\n",
        "When companies today deploy artificial intelligence programs, they are most likely using machine learning — so much so that the terms are often used interchangeably, and sometimes ambiguously. Machine learning is a subfield of artificial intelligence that gives computers the ability to learn without explicitly being programmed.\n",
        "\n",
        "“In just the last five or 10 years, machine learning has become a critical way, arguably the most important way, most parts of AI are done,” said MIT Sloan professorThomas W. Malone, the founding director of the MIT Center for Collective Intelligence. “So that's why some people use the terms AI and machine learning almost as synonymous … most of the current advances in AI have involved machine learning.”\n",
        "With the growing ubiquity of machine learning, everyone in business is likely to encounter it and will need some working knowledge about this field. A 2020 Deloitte survey found that 67% of companies are using machine learning, and 97% are using or planning to use it in the next year.\n",
        "\n",
        "From manufacturing to retail and banking to bakeries, even legacy companies are using machine learning to unlock new value or boost efficiency. “Machine learning is changing, or will change, every industry, and leaders need to understand the basic principles, the potential, and the limitations,” said MIT computer science professor Aleksander Madry, director of the MIT Center for Deployable Machine Learning.\n",
        "\n",
        "While not everyone needs to know the technical details, they should understand what the technology does and what it can and cannot do, Madry added. “I don’t think anyone can afford not to be aware of what’s happening.”\n",
        "\n",
        "That includes being aware of the social, societal, and ethical implications of machine learning. “It's important to engage and begin to understand these tools, and then think about how you're going to use them well. We have to use these [tools] for the good of everybody,” said Dr. Joan LaRovere, MBA ’16, a pediatric cardiac intensive care physician and co-founder of the nonprofit The Virtue Foundation. “AI has so much potential to do good, and we need to really keep that in our lenses as we're thinking about this. How do we use this to do good and better the world?”\n",
        "\n",
        "What is machine learning?\n",
        "Machine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior. Artificial intelligence systems are used to perform complex tasks in a way that is similar to how humans solve problems.\n",
        "\n",
        "The goal of AI is to create computer models that exhibit “intelligent behaviors” like humans, according to Boris Katz, a principal research scientist and head of the InfoLab Group at CSAIL. This means machines that can recognize a visual scene, understand a text written in natural language, or perform an action in the physical world.\n",
        "\n",
        "Machine learning is one way to use AI. It was defined in the 1950s by AI pioneer Arthur Samuel as “the field of study that gives computers the ability to learn without explicitly being programmed.”\n",
        "\n",
        "The definition holds true, according toMikey Shulman, a lecturer at MIT Sloan and head of machine learning at Kensho, which specializes in artificial intelligence for the finance and U.S. intelligence communities. He compared the traditional way of programming computers, or “software 1.0,” to baking, where a recipe calls for precise amounts of ingredients and tells the baker to mix for an exact amount of time. Traditional programming similarly requires creating detailed instructions for the computer to follow.\n",
        "\n",
        "But in some cases, writing a program for the machine to follow is time-consuming or impossible, such as training a computer to recognize pictures of different people. While humans can do this task easily, it’s difficult to tell a computer how to do it. Machine learning takes the approach of letting computers learn to program themselves through experience.\n",
        "\n",
        "Machine learning starts with data — numbers, photos, or text, like bank transactions, pictures of people or even bakery items, repair records, time series data from sensors, or sales reports. The data is gathered and prepared to be used as training data, or the information the machine learning model will be trained on. The more data, the better the program.\n",
        "\n",
        "From there, programmers choose a machine learning model to use, supply the data, and let the computer model train itself to find patterns or make predictions. Over time the human programmer can also tweak the model, including changing its parameters, to help push it toward more accurate results. (Research scientist Janelle Shane’s website AI Weirdness is an entertaining look at how machine learning algorithms learn and how they can get things wrong — as happened when an algorithm tried to generate recipes and created Chocolate Chicken Chicken Cake.)\n",
        "\n",
        "Some data is held out from the training data to be used as evaluation data, which tests how accurate the machine learning model is when it is shown new data. The result is a model that can be used in the future with different sets of data.\n",
        "\n",
        "Successful machine learning algorithms can do different things, Malone wrote in a recent research brief about AI and the future of work that was co-authored by MIT professor and CSAIL director Daniela Rus and Robert Laubacher, the associate director of the MIT Center for Collective Intelligence.\n",
        "\n",
        "“The function of a machine learning system can be descriptive, meaning that the system uses the data to explain what happened; predictive, meaning the system uses the data to predict what will happen; or prescriptive, meaning the system will use the data to make suggestions about what action to take,” the researchers wrote.\n",
        "\n",
        "There are three subcategories of machine learning:\n",
        "\n",
        "Supervised machine learning models are trained with labeled data sets, which allow the models to learn and grow more accurate over time. For example, an algorithm would be trained with pictures of dogs and other things, all labeled by humans, and the machine would learn ways to identify pictures of dogs on its own. Supervised machine learning is the most common type used today.\n",
        "\n",
        "In unsupervised machine learning, a program looks for patterns in unlabeled data. Unsupervised machine learning can find patterns or trends that people aren’t explicitly looking for. For example, an unsupervised machine learning program could look through online sales data and identify different types of clients making purchases.\n",
        "\n",
        "Reinforcement machine learning trains machines through trial and error to take the best action by establishing a reward system. Reinforcement learning can train models to play games or train autonomous vehicles to drive by telling the machine when it made the right decisions, which helps it learn over time what actions it should take.\n",
        "In the Work of the Future brief, Malone noted that machine learning is best suited for situations with lots of data — thousands or millions of examples, like recordings from previous conversations with customers, sensor logs from machines, or ATM transactions. For example, Google Translate was possible because it “trained” on the vast amount of information on the web, in different languages.\n",
        "\n",
        "In some cases, machine learning can gain insight or automate decision-making in cases where humans would not be able to, Madry said. “It may not only be more efficient and less costly to have an algorithm do this, but sometimes humans just literally are not able to do it,” he said.\n",
        "\n",
        "Google search is an example of something that humans can do, but never at the scale and speed at which the Google models are able to show potential answers every time a person types in a query, Malone said. “That’s not an example of computers putting people out of work. It's an example of computers doing things that would not have been remotely economically feasible if they had to be done by humans.”\n",
        "\n",
        "Machine learning is also associated with several other artificial intelligence subfields:\n",
        "\n",
        "Natural language processing\n",
        "\n",
        "Natural language processing is a field of machine learning in which machines learn to understand natural language as spoken and written by humans, instead of the data and numbers normally used to program computers. This allows machines to recognize language, understand it, and respond to it, as well as create new text and translate between languages. Natural language processing enables familiar technology like chatbots and digital assistants like Siri or Alexa.\n",
        "\n",
        "Neural networks\n",
        "\n",
        "Neural networks are a commonly used, specific class of machine learning algorithms. Artificial neural networks are modeled on the human brain, in which thousands or millions of processing nodes are interconnected and organized into layers.\n",
        "\n",
        "In an artificial neural network, cells, or nodes, are connected, with each cell processing inputs and producing an output that is sent to other neurons. Labeled data moves through the nodes, or cells, with each cell performing a different function. In a neural network trained to identify whether a picture contains a cat or not, the different nodes would assess the information and arrive at an output that indicates whether a picture features a cat.\n",
        "\n",
        "Deep learning\n",
        "\n",
        "Deep learning networks are neural networks with many layers. The layered network can process extensive amounts of data and determine the “weight” of each link in the network — for example, in an image recognition system, some layers of the neural network might detect individual features of a face, like eyes, nose, or mouth, while another layer would be able to tell whether those features appear in a way that indicates a face.\n",
        "\n",
        "Like neural networks, deep learning is modeled on the way the human brain works and powers many machine learning uses, like autonomous vehicles, chatbots, and medical diagnostics.\n",
        "\n",
        "“The more layers you have, the more potential you have for doing complex things well,” Malone said.\n",
        "\n",
        "Deep learning requires a great deal of computing power, which raises concerns about its economic and environmental sustainability.\n",
        "\n",
        "How businesses are using machine learning\n",
        "Machine learning is the core of some companies’ business models, like in the case of Netflix’s suggestions algorithm or Google’s search engine. Other companies are engaging deeply with machine learning, though it’s not their main business proposition.\n",
        "Others are still trying to determine how to use machine learning in a beneficial way. “In my opinion, one of the hardest problems in machine learning is figuring out what problems I can solve with machine learning,” Shulman said. “There’s still a gap in the understanding.”\n",
        "\n",
        "In a 2018 paper, researchers from the MIT Initiative on the Digital Economy outlined a 21-question rubric to determine whether a task is suitable for machine learning. The researchers found that no occupation will be untouched by machine learning, but no occupation is likely to be completely taken over by it. The way to unleash machine learning success, the researchers found, was to reorganize jobs into discrete tasks, some which can be done by machine learning, and others that require a human.\n",
        "\n",
        "Companies are already using machine learning in several ways, including:\n",
        "\n",
        "Recommendation algorithms. The recommendation engines behind Netflix and YouTube suggestions, what information appears on your Facebook feed, and product recommendations are fueled by machine learning. “[The algorithms] are trying to learn our preferences,” Madry said. “They want to learn, like on Twitter, what tweets we want them to show us, on Facebook, what ads to display, what posts or liked content to share with us.”\n",
        "\n",
        "Image analysis and object detection. Machine learning can analyze images for different information, like learning to identify people and tell them apart — though facial recognition algorithms are controversial. Business uses for this vary. Shulman noted that hedge funds famously use machine learning to analyze the number of cars in parking lots, which helps them learn how companies are performing and make good bets.\n",
        "\n",
        "Fraud detection. Machines can analyze patterns, like how someone normally spends or where they normally shop, to identify potentially fraudulent credit card transactions, log-in attempts, or spam emails.\n",
        "\n",
        "Automatic helplines or chatbots. Many companies are deploying online chatbots, in which customers or clients don’t speak to humans, but instead interact with a machine. These algorithms use machine learning and natural language processing, with the bots learning from records of past conversations to come up with appropriate responses.\n",
        "\n",
        "Self-driving cars. Much of the technology behind self-driving cars is based on machine learning, deep learning in particular.\n",
        "\n",
        "Medical imaging and diagnostics. Machine learning programs can be trained to examine medical images or other information and look for certain markers of illness, like a tool that can predict cancer risk based on a mammogram.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UvvM9VokceQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdrBfEHscybU",
        "outputId": "8f0b0c73-929d-4229-f43b-e30d2c278405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5163"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence Selection and Question Generation\n",
        "In order to generate questions we must first identify significant sentences that hold fact or knowledge. There two broad ways to do this:\n",
        "\n",
        "### a. Name Entity Recognition:\n",
        "We can identify important names, locations and formulate them as questions.\n",
        "If we want to test grammar skills we can idenity instead verbs, nouns and   other adpositions.\n",
        "\n",
        "### b. Keyword Extraction:\n",
        "We identify important keywords from our text, and then formulate questions such that those keywords as answers. We will explore this method in this notebook.\n",
        "\n",
        "### Question Generation:\n",
        "For generating question,  we have two broad ways:<br>\n",
        "a. Either we can train a model that takes answer and context as input, and generates a question. This would be a sequence to sequence problem. This is opposite of Question Answering task where we feed the model and Question, and context and it generates a answer. We can use the same dataset instead to formulate questions.  The advantage of this method is we can proper questions.\n",
        "\n",
        "b. Another simple way we can formulate questions, is  just by replacing the keyword in the original text with a blank. This would generate only fill in the blanks type declarative questions. It will be very straightforward and easy to implement. The advantage is it's easy to implement and we don't need any machine learning model.\n",
        "\n",
        "We explore both ways in this notebook, but we preferred the second method in production."
      ],
      "metadata": {
        "id": "mCNg3f8pvhCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identifying Keywords"
      ],
      "metadata": {
        "id": "6HlE_VahlX1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keybert > /dev/null\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from keybert import KeyBERT\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "\n",
        "# we use nltk library to tokenize our text\n",
        "nltk.download('punkt')\n",
        "\n",
        "# KeyBert uses BERT-embeddings and simple cosine similarity to find the sub-phrases in a document that are the most similar to the document itself.\n",
        "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "kw_model = KeyBERT(sentence_model)\n",
        "\n",
        "def get_keywords(text):\n",
        "    \"\"\"\n",
        "    Given @input text, identify important keywords.\n",
        "    Here we use Sentence Transformer to extract keywords that best describe the text\n",
        "    \"\"\"\n",
        "    keywords_with_scores = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), top_n=5, stop_words='english')\n",
        "    keywords = [kw[0] for kw in keywords_with_scores]\n",
        "    scores = [kw[1] for kw in keywords_with_scores]\n",
        "    return keywords\n",
        "\n",
        "def tokenize_sentences(text):\n",
        "    \"\"\"\n",
        "    Given a @text input, returns tokenized sentences\n",
        "    \"\"\"\n",
        "    sentences = [sent_tokenize(text)]\n",
        "    sentences = [sentence for paragraph in sentences for sentence in paragraph]\n",
        "\n",
        "    # Remove sentences shorter than 20 letters.\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences\n",
        "\n",
        "def get_sentences_for_keyword(kw_model, sentences, lemmatizer):\n",
        "    \"\"\"\n",
        "    @kw_model: keyBERT model to extract keywords\n",
        "    @sentences: list of tokenized sentences\n",
        "    returns a map with keywords as keys mapped to the sentences they appear in.\n",
        "    \"\"\"\n",
        "    keyword_sentences = {}\n",
        "    for sentence in sentences:\n",
        "        keywords_found = [kw[0] for kw in kw_model.extract_keywords(sentence, keyphrase_ngram_range=(1, 2), top_n=10) if len(kw[0]) > 2]\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key] = keyword_sentences.get(key, [])\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    return keyword_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R05iPojFu6j9",
        "outputId": "062c4a2f-a9f7-4489-d3d1-93b82ef0e481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-15 16:54:47.682 Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-15 16:54:51.989 Use pytorch device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize text into sentences\n",
        "# Install the required module\n",
        "!pip install keybert\n",
        "!pip install nltk\n",
        "\n",
        "# Import the required modules\n",
        "from keybert import KeyBERT\n",
        "import nltk\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "# Download the required NLTK data\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define the function to get sentences for a keyword\n",
        "def get_sentences_for_keyword(kw_model, sentences):\n",
        "    keyword_to_sentences_map = {}\n",
        "    sentences = sent_tokenize(text)\n",
        "    for sentence in sentences:\n",
        "        # Tokenize the sentence\n",
        "        sentence_tokens = nltk.word_tokenize(sentence)\n",
        "        # Extract keywords from the sentence\n",
        "        keywords = kw_model.extract_keywords(' '.join(sentence_tokens))\n",
        "        # Add the sentence to the map for each extracted keyword\n",
        "        for keyword in keywords:\n",
        "            if keyword not in keyword_to_sentences_map:\n",
        "                keyword_to_sentences_map[keyword] = []\n",
        "            keyword_to_sentences_map[keyword].append(sentence)\n",
        "    return keyword_to_sentences_map\n",
        "\n",
        "# Create a KeyBERT model\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "# Get sentences for each keyword\n",
        "keyword_to_sentences_map = get_sentences_for_keyword(kw_model, sentences)\n",
        "\n",
        "# Print the results\n",
        "for keyword in keyword_to_sentences_map:\n",
        "    print(keyword, \" : \", keyword_to_sentences_map[keyword], \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoVV0zs9nuNY",
        "outputId": "5b4a2f2d-cf4e-42b3-9013-801436bd01b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keybert in /usr/local/lib/python3.10/dist-packages (0.8.4)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from keybert) (2.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.25.2)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.16.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (3.3.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.37.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (23.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.3.8->keybert) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('chatbots', 0.5151)  :  [' Machine learning is behind chatbots and predictive text, language translation apps, the shows Netflix suggests to you, and how your social media feeds are presented.'] \n",
            "\n",
            "('learning', 0.4184)  :  [' Machine learning is behind chatbots and predictive text, language translation apps, the shows Netflix suggests to you, and how your social media feeds are presented.', 'It was defined in the 1950s by AI pioneer Arthur Samuel as “the field of study that gives computers the ability to learn without explicitly being programmed.”\\n\\nThe definition holds true, according toMikey Shulman, a lecturer at MIT Sloan and head of machine learning at Kensho, which specializes in artificial intelligence for the finance and U.S. intelligence communities.'] \n",
            "\n",
            "('feeds', 0.4059)  :  [' Machine learning is behind chatbots and predictive text, language translation apps, the shows Netflix suggests to you, and how your social media feeds are presented.'] \n",
            "\n",
            "('netflix', 0.3828)  :  [' Machine learning is behind chatbots and predictive text, language translation apps, the shows Netflix suggests to you, and how your social media feeds are presented.'] \n",
            "\n",
            "('language', 0.3544)  :  [' Machine learning is behind chatbots and predictive text, language translation apps, the shows Netflix suggests to you, and how your social media feeds are presented.'] \n",
            "\n",
            "('medical', 0.4126)  :  ['It powers autonomous vehicles and machines that can diagnose medical conditions based on images.'] \n",
            "\n",
            "('machines', 0.3849)  :  ['It powers autonomous vehicles and machines that can diagnose medical conditions based on images.'] \n",
            "\n",
            "('autonomous', 0.3616)  :  ['It powers autonomous vehicles and machines that can diagnose medical conditions based on images.'] \n",
            "\n",
            "('diagnose', 0.3533)  :  ['It powers autonomous vehicles and machines that can diagnose medical conditions based on images.'] \n",
            "\n",
            "('images', 0.3378)  :  ['It powers autonomous vehicles and machines that can diagnose medical conditions based on images.'] \n",
            "\n",
            "('learning', 0.3046)  :  ['When companies today deploy artificial intelligence programs, they are most likely using machine learning — so much so that the terms are often used interchangeably, and sometimes ambiguously.'] \n",
            "\n",
            "('programs', 0.2835)  :  ['When companies today deploy artificial intelligence programs, they are most likely using machine learning — so much so that the terms are often used interchangeably, and sometimes ambiguously.'] \n",
            "\n",
            "('interchangeably', 0.2828)  :  ['When companies today deploy artificial intelligence programs, they are most likely using machine learning — so much so that the terms are often used interchangeably, and sometimes ambiguously.'] \n",
            "\n",
            "('machine', 0.271)  :  ['When companies today deploy artificial intelligence programs, they are most likely using machine learning — so much so that the terms are often used interchangeably, and sometimes ambiguously.'] \n",
            "\n",
            "('artificial', 0.2503)  :  ['When companies today deploy artificial intelligence programs, they are most likely using machine learning — so much so that the terms are often used interchangeably, and sometimes ambiguously.'] \n",
            "\n",
            "('learning', 0.4552)  :  ['Machine learning is a subfield of artificial intelligence that gives computers the ability to learn without explicitly being programmed.'] \n",
            "\n",
            "('programmed', 0.4112)  :  ['Machine learning is a subfield of artificial intelligence that gives computers the ability to learn without explicitly being programmed.'] \n",
            "\n",
            "('machine', 0.3596)  :  ['Machine learning is a subfield of artificial intelligence that gives computers the ability to learn without explicitly being programmed.'] \n",
            "\n",
            "('computers', 0.3375)  :  ['Machine learning is a subfield of artificial intelligence that gives computers the ability to learn without explicitly being programmed.'] \n",
            "\n",
            "('intelligence', 0.3328)  :  ['Machine learning is a subfield of artificial intelligence that gives computers the ability to learn without explicitly being programmed.'] \n",
            "\n",
            "('ai', 0.5645)  :  ['“In just the last five or 10 years, machine learning has become a critical way, arguably the most important way, most parts of AI are done,” said MIT Sloan professorThomas W. Malone, the founding director of the MIT Center for Collective Intelligence.'] \n",
            "\n",
            "('learning', 0.4443)  :  ['“In just the last five or 10 years, machine learning has become a critical way, arguably the most important way, most parts of AI are done,” said MIT Sloan professorThomas W. Malone, the founding director of the MIT Center for Collective Intelligence.'] \n",
            "\n",
            "('intelligence', 0.3998)  :  ['“In just the last five or 10 years, machine learning has become a critical way, arguably the most important way, most parts of AI are done,” said MIT Sloan professorThomas W. Malone, the founding director of the MIT Center for Collective Intelligence.'] \n",
            "\n",
            "('machine', 0.356)  :  ['“In just the last five or 10 years, machine learning has become a critical way, arguably the most important way, most parts of AI are done,” said MIT Sloan professorThomas W. Malone, the founding director of the MIT Center for Collective Intelligence.'] \n",
            "\n",
            "('critical', 0.2645)  :  ['“In just the last five or 10 years, machine learning has become a critical way, arguably the most important way, most parts of AI are done,” said MIT Sloan professorThomas W. Malone, the founding director of the MIT Center for Collective Intelligence.'] \n",
            "\n",
            "('ai', 0.5456)  :  [\"“So that's why some people use the terms AI and machine learning almost as synonymous … most of the current advances in AI have involved machine learning.”\\nWith the growing ubiquity of machine learning, everyone in business is likely to encounter it and will need some working knowledge about this field.\"] \n",
            "\n",
            "('learning', 0.3487)  :  [\"“So that's why some people use the terms AI and machine learning almost as synonymous … most of the current advances in AI have involved machine learning.”\\nWith the growing ubiquity of machine learning, everyone in business is likely to encounter it and will need some working knowledge about this field.\"] \n",
            "\n",
            "('machine', 0.3098)  :  [\"“So that's why some people use the terms AI and machine learning almost as synonymous … most of the current advances in AI have involved machine learning.”\\nWith the growing ubiquity of machine learning, everyone in business is likely to encounter it and will need some working knowledge about this field.\"] \n",
            "\n",
            "('knowledge', 0.303)  :  [\"“So that's why some people use the terms AI and machine learning almost as synonymous … most of the current advances in AI have involved machine learning.”\\nWith the growing ubiquity of machine learning, everyone in business is likely to encounter it and will need some working knowledge about this field.\"] \n",
            "\n",
            "('business', 0.2028)  :  [\"“So that's why some people use the terms AI and machine learning almost as synonymous … most of the current advances in AI have involved machine learning.”\\nWith the growing ubiquity of machine learning, everyone in business is likely to encounter it and will need some working knowledge about this field.\"] \n",
            "\n",
            "('deloitte', 0.371)  :  ['A 2020 Deloitte survey found that 67% of companies are using machine learning, and 97% are using or planning to use it in the next year.'] \n",
            "\n",
            "('learning', 0.2684)  :  ['A 2020 Deloitte survey found that 67% of companies are using machine learning, and 97% are using or planning to use it in the next year.'] \n",
            "\n",
            "('companies', 0.2528)  :  ['A 2020 Deloitte survey found that 67% of companies are using machine learning, and 97% are using or planning to use it in the next year.'] \n",
            "\n",
            "('machine', 0.2411)  :  ['A 2020 Deloitte survey found that 67% of companies are using machine learning, and 97% are using or planning to use it in the next year.'] \n",
            "\n",
            "('using', 0.2403)  :  ['A 2020 Deloitte survey found that 67% of companies are using machine learning, and 97% are using or planning to use it in the next year.'] \n",
            "\n",
            "('learning', 0.383)  :  ['From manufacturing to retail and banking to bakeries, even legacy companies are using machine learning to unlock new value or boost efficiency.'] \n",
            "\n",
            "('companies', 0.3479)  :  ['From manufacturing to retail and banking to bakeries, even legacy companies are using machine learning to unlock new value or boost efficiency.'] \n",
            "\n",
            "('machine', 0.3433)  :  ['From manufacturing to retail and banking to bakeries, even legacy companies are using machine learning to unlock new value or boost efficiency.'] \n",
            "\n",
            "('manufacturing', 0.3356)  :  ['From manufacturing to retail and banking to bakeries, even legacy companies are using machine learning to unlock new value or boost efficiency.'] \n",
            "\n",
            "('efficiency', 0.3218)  :  ['From manufacturing to retail and banking to bakeries, even legacy companies are using machine learning to unlock new value or boost efficiency.'] \n",
            "\n",
            "('learning', 0.4675)  :  ['“Machine learning is changing, or will change, every industry, and leaders need to understand the basic principles, the potential, and the limitations,” said MIT computer science professor Aleksander Madry, director of the MIT Center for Deployable Machine Learning.'] \n",
            "\n",
            "('machine', 0.3352)  :  ['“Machine learning is changing, or will change, every industry, and leaders need to understand the basic principles, the potential, and the limitations,” said MIT computer science professor Aleksander Madry, director of the MIT Center for Deployable Machine Learning.'] \n",
            "\n",
            "('deployable', 0.2791)  :  ['“Machine learning is changing, or will change, every industry, and leaders need to understand the basic principles, the potential, and the limitations,” said MIT computer science professor Aleksander Madry, director of the MIT Center for Deployable Machine Learning.'] \n",
            "\n",
            "('changing', 0.2734)  :  ['“Machine learning is changing, or will change, every industry, and leaders need to understand the basic principles, the potential, and the limitations,” said MIT computer science professor Aleksander Madry, director of the MIT Center for Deployable Machine Learning.'] \n",
            "\n",
            "('limitations', 0.2714)  :  ['“Machine learning is changing, or will change, every industry, and leaders need to understand the basic principles, the potential, and the limitations,” said MIT computer science professor Aleksander Madry, director of the MIT Center for Deployable Machine Learning.'] \n",
            "\n",
            "('madry', 0.4764)  :  ['While not everyone needs to know the technical details, they should understand what the technology does and what it can and cannot do, Madry added.'] \n",
            "\n",
            "('technology', 0.4377)  :  ['While not everyone needs to know the technical details, they should understand what the technology does and what it can and cannot do, Madry added.'] \n",
            "\n",
            "('technical', 0.3697)  :  ['While not everyone needs to know the technical details, they should understand what the technology does and what it can and cannot do, Madry added.'] \n",
            "\n",
            "('understand', 0.1912)  :  ['While not everyone needs to know the technical details, they should understand what the technology does and what it can and cannot do, Madry added.'] \n",
            "\n",
            "('needs', 0.1858)  :  ['While not everyone needs to know the technical details, they should understand what the technology does and what it can and cannot do, Madry added.'] \n",
            "\n",
            "('ethical', 0.4485)  :  ['“I don’t think anyone can afford not to be aware of what’s happening.”\\n\\nThat includes being aware of the social, societal, and ethical implications of machine learning.'] \n",
            "\n",
            "('learning', 0.4037)  :  ['“I don’t think anyone can afford not to be aware of what’s happening.”\\n\\nThat includes being aware of the social, societal, and ethical implications of machine learning.'] \n",
            "\n",
            "('societal', 0.3366)  :  ['“I don’t think anyone can afford not to be aware of what’s happening.”\\n\\nThat includes being aware of the social, societal, and ethical implications of machine learning.'] \n",
            "\n",
            "('social', 0.3102)  :  ['“I don’t think anyone can afford not to be aware of what’s happening.”\\n\\nThat includes being aware of the social, societal, and ethical implications of machine learning.'] \n",
            "\n",
            "('aware', 0.3055)  :  ['“I don’t think anyone can afford not to be aware of what’s happening.”\\n\\nThat includes being aware of the social, societal, and ethical implications of machine learning.'] \n",
            "\n",
            "('tools', 0.5963)  :  [\"“It's important to engage and begin to understand these tools, and then think about how you're going to use them well.\"] \n",
            "\n",
            "('engage', 0.3391)  :  [\"“It's important to engage and begin to understand these tools, and then think about how you're going to use them well.\"] \n",
            "\n",
            "('understand', 0.2898)  :  [\"“It's important to engage and begin to understand these tools, and then think about how you're going to use them well.\"] \n",
            "\n",
            "('begin', 0.2802)  :  [\"“It's important to engage and begin to understand these tools, and then think about how you're going to use them well.\"] \n",
            "\n",
            "('use', 0.2518)  :  [\"“It's important to engage and begin to understand these tools, and then think about how you're going to use them well.\"] \n",
            "\n",
            "('tools', 0.4422)  :  ['We have to use these [tools] for the good of everybody,” said Dr. Joan LaRovere, MBA ’16, a pediatric cardiac intensive care physician and co-founder of the nonprofit The Virtue Foundation.'] \n",
            "\n",
            "('virtue', 0.3628)  :  ['We have to use these [tools] for the good of everybody,” said Dr. Joan LaRovere, MBA ’16, a pediatric cardiac intensive care physician and co-founder of the nonprofit The Virtue Foundation.'] \n",
            "\n",
            "('physician', 0.3477)  :  ['We have to use these [tools] for the good of everybody,” said Dr. Joan LaRovere, MBA ’16, a pediatric cardiac intensive care physician and co-founder of the nonprofit The Virtue Foundation.'] \n",
            "\n",
            "('founder', 0.3085)  :  ['We have to use these [tools] for the good of everybody,” said Dr. Joan LaRovere, MBA ’16, a pediatric cardiac intensive care physician and co-founder of the nonprofit The Virtue Foundation.'] \n",
            "\n",
            "('cardiac', 0.2876)  :  ['We have to use these [tools] for the good of everybody,” said Dr. Joan LaRovere, MBA ’16, a pediatric cardiac intensive care physician and co-founder of the nonprofit The Virtue Foundation.'] \n",
            "\n",
            "('ai', 0.5751)  :  [\"“AI has so much potential to do good, and we need to really keep that in our lenses as we're thinking about this.\"] \n",
            "\n",
            "('lenses', 0.4437)  :  [\"“AI has so much potential to do good, and we need to really keep that in our lenses as we're thinking about this.\"] \n",
            "\n",
            "('potential', 0.2739)  :  [\"“AI has so much potential to do good, and we need to really keep that in our lenses as we're thinking about this.\"] \n",
            "\n",
            "('thinking', 0.2001)  :  [\"“AI has so much potential to do good, and we need to really keep that in our lenses as we're thinking about this.\"] \n",
            "\n",
            "('really', 0.176)  :  [\"“AI has so much potential to do good, and we need to really keep that in our lenses as we're thinking about this.\"] \n",
            "\n",
            "('learning', 0.5114)  :  ['How do we use this to do good and better the world?”\\n\\nWhat is machine learning?'] \n",
            "\n",
            "('machine', 0.4121)  :  ['How do we use this to do good and better the world?”\\n\\nWhat is machine learning?'] \n",
            "\n",
            "('world', 0.2792)  :  ['How do we use this to do good and better the world?”\\n\\nWhat is machine learning?'] \n",
            "\n",
            "('use', 0.2389)  :  ['How do we use this to do good and better the world?”\\n\\nWhat is machine learning?'] \n",
            "\n",
            "('better', 0.1357)  :  ['How do we use this to do good and better the world?”\\n\\nWhat is machine learning?'] \n",
            "\n",
            "('machine', 0.3783)  :  ['Machine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior.'] \n",
            "\n",
            "('learning', 0.3743)  :  ['Machine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior.'] \n",
            "\n",
            "('intelligent', 0.3662)  :  ['Machine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior.'] \n",
            "\n",
            "('intelligence', 0.3617)  :  ['Machine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior.'] \n",
            "\n",
            "('artificial', 0.3134)  :  ['Machine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior.'] \n",
            "\n",
            "('intelligence', 0.4326)  :  ['Artificial intelligence systems are used to perform complex tasks in a way that is similar to how humans solve problems.'] \n",
            "\n",
            "('artificial', 0.3955)  :  ['Artificial intelligence systems are used to perform complex tasks in a way that is similar to how humans solve problems.'] \n",
            "\n",
            "('systems', 0.3886)  :  ['Artificial intelligence systems are used to perform complex tasks in a way that is similar to how humans solve problems.'] \n",
            "\n",
            "('tasks', 0.3845)  :  ['Artificial intelligence systems are used to perform complex tasks in a way that is similar to how humans solve problems.'] \n",
            "\n",
            "('complex', 0.3817)  :  ['Artificial intelligence systems are used to perform complex tasks in a way that is similar to how humans solve problems.'] \n",
            "\n",
            "('ai', 0.6175)  :  ['The goal of AI is to create computer models that exhibit “intelligent behaviors” like humans, according to Boris Katz, a principal research scientist and head of the InfoLab Group at CSAIL.'] \n",
            "\n",
            "('intelligent', 0.4577)  :  ['The goal of AI is to create computer models that exhibit “intelligent behaviors” like humans, according to Boris Katz, a principal research scientist and head of the InfoLab Group at CSAIL.'] \n",
            "\n",
            "('models', 0.3809)  :  ['The goal of AI is to create computer models that exhibit “intelligent behaviors” like humans, according to Boris Katz, a principal research scientist and head of the InfoLab Group at CSAIL.'] \n",
            "\n",
            "('behaviors', 0.3797)  :  ['The goal of AI is to create computer models that exhibit “intelligent behaviors” like humans, according to Boris Katz, a principal research scientist and head of the InfoLab Group at CSAIL.'] \n",
            "\n",
            "('create', 0.2838)  :  ['The goal of AI is to create computer models that exhibit “intelligent behaviors” like humans, according to Boris Katz, a principal research scientist and head of the InfoLab Group at CSAIL.'] \n",
            "\n",
            "('machines', 0.5289)  :  ['This means machines that can recognize a visual scene, understand a text written in natural language, or perform an action in the physical world.'] \n",
            "\n",
            "('visual', 0.4558)  :  ['This means machines that can recognize a visual scene, understand a text written in natural language, or perform an action in the physical world.'] \n",
            "\n",
            "('language', 0.4287)  :  ['This means machines that can recognize a visual scene, understand a text written in natural language, or perform an action in the physical world.'] \n",
            "\n",
            "('text', 0.4188)  :  ['This means machines that can recognize a visual scene, understand a text written in natural language, or perform an action in the physical world.'] \n",
            "\n",
            "('physical', 0.3513)  :  ['This means machines that can recognize a visual scene, understand a text written in natural language, or perform an action in the physical world.'] \n",
            "\n",
            "('ai', 0.6137)  :  ['Machine learning is one way to use AI.'] \n",
            "\n",
            "('learning', 0.5151)  :  ['Machine learning is one way to use AI.'] \n",
            "\n",
            "('machine', 0.3143)  :  ['Machine learning is one way to use AI.'] \n",
            "\n",
            "('use', 0.2821)  :  ['Machine learning is one way to use AI.'] \n",
            "\n",
            "('way', 0.164)  :  ['Machine learning is one way to use AI.'] \n",
            "\n",
            "('ai', 0.5427)  :  ['It was defined in the 1950s by AI pioneer Arthur Samuel as “the field of study that gives computers the ability to learn without explicitly being programmed.”\\n\\nThe definition holds true, according toMikey Shulman, a lecturer at MIT Sloan and head of machine learning at Kensho, which specializes in artificial intelligence for the finance and U.S. intelligence communities.'] \n",
            "\n",
            "('intelligence', 0.4249)  :  ['It was defined in the 1950s by AI pioneer Arthur Samuel as “the field of study that gives computers the ability to learn without explicitly being programmed.”\\n\\nThe definition holds true, according toMikey Shulman, a lecturer at MIT Sloan and head of machine learning at Kensho, which specializes in artificial intelligence for the finance and U.S. intelligence communities.'] \n",
            "\n",
            "('programmed', 0.414)  :  ['It was defined in the 1950s by AI pioneer Arthur Samuel as “the field of study that gives computers the ability to learn without explicitly being programmed.”\\n\\nThe definition holds true, according toMikey Shulman, a lecturer at MIT Sloan and head of machine learning at Kensho, which specializes in artificial intelligence for the finance and U.S. intelligence communities.'] \n",
            "\n",
            "('definition', 0.3959)  :  ['It was defined in the 1950s by AI pioneer Arthur Samuel as “the field of study that gives computers the ability to learn without explicitly being programmed.”\\n\\nThe definition holds true, according toMikey Shulman, a lecturer at MIT Sloan and head of machine learning at Kensho, which specializes in artificial intelligence for the finance and U.S. intelligence communities.'] \n",
            "\n",
            "('baking', 0.5269)  :  ['He compared the traditional way of programming computers, or “software 1.0,” to baking, where a recipe calls for precise amounts of ingredients and tells the baker to mix for an exact amount of time.'] \n",
            "\n",
            "('programming', 0.4801)  :  ['He compared the traditional way of programming computers, or “software 1.0,” to baking, where a recipe calls for precise amounts of ingredients and tells the baker to mix for an exact amount of time.'] \n",
            "\n",
            "('software', 0.4279)  :  ['He compared the traditional way of programming computers, or “software 1.0,” to baking, where a recipe calls for precise amounts of ingredients and tells the baker to mix for an exact amount of time.'] \n",
            "\n",
            "('recipe', 0.3936)  :  ['He compared the traditional way of programming computers, or “software 1.0,” to baking, where a recipe calls for precise amounts of ingredients and tells the baker to mix for an exact amount of time.'] \n",
            "\n",
            "('baker', 0.3589)  :  ['He compared the traditional way of programming computers, or “software 1.0,” to baking, where a recipe calls for precise amounts of ingredients and tells the baker to mix for an exact amount of time.'] \n",
            "\n",
            "('programming', 0.5951)  :  ['Traditional programming similarly requires creating detailed instructions for the computer to follow.'] \n",
            "\n",
            "('instructions', 0.3663)  :  ['Traditional programming similarly requires creating detailed instructions for the computer to follow.'] \n",
            "\n",
            "('computer', 0.2884)  :  ['Traditional programming similarly requires creating detailed instructions for the computer to follow.'] \n",
            "\n",
            "('creating', 0.2568)  :  ['Traditional programming similarly requires creating detailed instructions for the computer to follow.'] \n",
            "\n",
            "('requires', 0.2392)  :  ['Traditional programming similarly requires creating detailed instructions for the computer to follow.'] \n",
            "\n",
            "('program', 0.474)  :  ['But in some cases, writing a program for the machine to follow is time-consuming or impossible, such as training a computer to recognize pictures of different people.'] \n",
            "\n",
            "('machine', 0.3508)  :  ['But in some cases, writing a program for the machine to follow is time-consuming or impossible, such as training a computer to recognize pictures of different people.'] \n",
            "\n",
            "('computer', 0.3172)  :  ['But in some cases, writing a program for the machine to follow is time-consuming or impossible, such as training a computer to recognize pictures of different people.'] \n",
            "\n",
            "('recognize', 0.2942)  :  ['But in some cases, writing a program for the machine to follow is time-consuming or impossible, such as training a computer to recognize pictures of different people.'] \n",
            "\n",
            "('training', 0.2841)  :  ['But in some cases, writing a program for the machine to follow is time-consuming or impossible, such as training a computer to recognize pictures of different people.'] \n",
            "\n",
            "('easily', 0.3947)  :  ['While humans can do this task easily, it’s difficult to tell a computer how to do it.'] \n",
            "\n",
            "('computer', 0.3114)  :  ['While humans can do this task easily, it’s difficult to tell a computer how to do it.'] \n",
            "\n",
            "('difficult', 0.2699)  :  ['While humans can do this task easily, it’s difficult to tell a computer how to do it.'] \n",
            "\n",
            "('humans', 0.2538)  :  ['While humans can do this task easily, it’s difficult to tell a computer how to do it.'] \n",
            "\n",
            "('task', 0.2486)  :  ['While humans can do this task easily, it’s difficult to tell a computer how to do it.'] \n",
            "\n",
            "('learning', 0.4946)  :  ['Machine learning takes the approach of letting computers learn to program themselves through experience.'] \n",
            "\n",
            "('program', 0.449)  :  ['Machine learning takes the approach of letting computers learn to program themselves through experience.'] \n",
            "\n",
            "('learn', 0.3676)  :  ['Machine learning takes the approach of letting computers learn to program themselves through experience.'] \n",
            "\n",
            "('computers', 0.3584)  :  ['Machine learning takes the approach of letting computers learn to program themselves through experience.'] \n",
            "\n",
            "('machine', 0.3486)  :  ['Machine learning takes the approach of letting computers learn to program themselves through experience.'] \n",
            "\n",
            "('data', 0.4786)  :  ['Machine learning starts with data — numbers, photos, or text, like bank transactions, pictures of people or even bakery items, repair records, time series data from sensors, or sales reports.'] \n",
            "\n",
            "('learning', 0.3217)  :  ['Machine learning starts with data — numbers, photos, or text, like bank transactions, pictures of people or even bakery items, repair records, time series data from sensors, or sales reports.'] \n",
            "\n",
            "('machine', 0.303)  :  ['Machine learning starts with data — numbers, photos, or text, like bank transactions, pictures of people or even bakery items, repair records, time series data from sensors, or sales reports.'] \n",
            "\n",
            "('records', 0.2666)  :  ['Machine learning starts with data — numbers, photos, or text, like bank transactions, pictures of people or even bakery items, repair records, time series data from sensors, or sales reports.'] \n",
            "\n",
            "('photos', 0.2628)  :  ['Machine learning starts with data — numbers, photos, or text, like bank transactions, pictures of people or even bakery items, repair records, time series data from sensors, or sales reports.'] \n",
            "\n",
            "('data', 0.5261)  :  ['The data is gathered and prepared to be used as training data, or the information the machine learning model will be trained on.'] \n",
            "\n",
            "('training', 0.4075)  :  ['The data is gathered and prepared to be used as training data, or the information the machine learning model will be trained on.'] \n",
            "\n",
            "('information', 0.3965)  :  ['The data is gathered and prepared to be used as training data, or the information the machine learning model will be trained on.'] \n",
            "\n",
            "('trained', 0.3729)  :  ['The data is gathered and prepared to be used as training data, or the information the machine learning model will be trained on.'] \n",
            "\n",
            "('learning', 0.37)  :  ['The data is gathered and prepared to be used as training data, or the information the machine learning model will be trained on.'] \n",
            "\n",
            "('data', 0.5499)  :  ['The more data, the better the program.'] \n",
            "\n",
            "('program', 0.442)  :  ['The more data, the better the program.'] \n",
            "\n",
            "('better', 0.2593)  :  ['The more data, the better the program.'] \n",
            "\n",
            "('programmers', 0.4623)  :  ['From there, programmers choose a machine learning model to use, supply the data, and let the computer model train itself to find patterns or make predictions.'] \n",
            "\n",
            "('learning', 0.3706)  :  ['From there, programmers choose a machine learning model to use, supply the data, and let the computer model train itself to find patterns or make predictions.'] \n",
            "\n",
            "('patterns', 0.3319)  :  ['From there, programmers choose a machine learning model to use, supply the data, and let the computer model train itself to find patterns or make predictions.'] \n",
            "\n",
            "('data', 0.3165)  :  ['From there, programmers choose a machine learning model to use, supply the data, and let the computer model train itself to find patterns or make predictions.'] \n",
            "\n",
            "('model', 0.2844)  :  ['From there, programmers choose a machine learning model to use, supply the data, and let the computer model train itself to find patterns or make predictions.'] \n",
            "\n",
            "('model', 0.4036)  :  ['Over time the human programmer can also tweak the model, including changing its parameters, to help push it toward more accurate results.'] \n",
            "\n",
            "('tweak', 0.3654)  :  ['Over time the human programmer can also tweak the model, including changing its parameters, to help push it toward more accurate results.'] \n",
            "\n",
            "('changing', 0.347)  :  ['Over time the human programmer can also tweak the model, including changing its parameters, to help push it toward more accurate results.'] \n",
            "\n",
            "('programmer', 0.3184)  :  ['Over time the human programmer can also tweak the model, including changing its parameters, to help push it toward more accurate results.'] \n",
            "\n",
            "('parameters', 0.3148)  :  ['Over time the human programmer can also tweak the model, including changing its parameters, to help push it toward more accurate results.'] \n",
            "\n",
            "('ai', 0.541)  :  ['(Research scientist Janelle Shane’s website AI Weirdness is an entertaining look at how machine learning algorithms learn and how they can get things wrong — as happened when an algorithm tried to generate recipes and created Chocolate Chicken Chicken Cake.)'] \n",
            "\n",
            "('weirdness', 0.417)  :  ['(Research scientist Janelle Shane’s website AI Weirdness is an entertaining look at how machine learning algorithms learn and how they can get things wrong — as happened when an algorithm tried to generate recipes and created Chocolate Chicken Chicken Cake.)'] \n",
            "\n",
            "('algorithms', 0.3686)  :  ['(Research scientist Janelle Shane’s website AI Weirdness is an entertaining look at how machine learning algorithms learn and how they can get things wrong — as happened when an algorithm tried to generate recipes and created Chocolate Chicken Chicken Cake.)'] \n",
            "\n",
            "('learning', 0.3355)  :  ['(Research scientist Janelle Shane’s website AI Weirdness is an entertaining look at how machine learning algorithms learn and how they can get things wrong — as happened when an algorithm tried to generate recipes and created Chocolate Chicken Chicken Cake.)'] \n",
            "\n",
            "('algorithm', 0.3118)  :  ['(Research scientist Janelle Shane’s website AI Weirdness is an entertaining look at how machine learning algorithms learn and how they can get things wrong — as happened when an algorithm tried to generate recipes and created Chocolate Chicken Chicken Cake.)'] \n",
            "\n",
            "('data', 0.4639)  :  ['Some data is held out from the training data to be used as evaluation data, which tests how accurate the machine learning model is when it is shown new data.'] \n",
            "\n",
            "('evaluation', 0.3988)  :  ['Some data is held out from the training data to be used as evaluation data, which tests how accurate the machine learning model is when it is shown new data.'] \n",
            "\n",
            "('training', 0.323)  :  ['Some data is held out from the training data to be used as evaluation data, which tests how accurate the machine learning model is when it is shown new data.'] \n",
            "\n",
            "('tests', 0.3085)  :  ['Some data is held out from the training data to be used as evaluation data, which tests how accurate the machine learning model is when it is shown new data.'] \n",
            "\n",
            "('learning', 0.3012)  :  ['Some data is held out from the training data to be used as evaluation data, which tests how accurate the machine learning model is when it is shown new data.'] \n",
            "\n",
            "('data', 0.4723)  :  ['The result is a model that can be used in the future with different sets of data.'] \n",
            "\n",
            "('model', 0.4569)  :  ['The result is a model that can be used in the future with different sets of data.'] \n",
            "\n",
            "('future', 0.3896)  :  ['The result is a model that can be used in the future with different sets of data.'] \n",
            "\n",
            "('result', 0.2777)  :  ['The result is a model that can be used in the future with different sets of data.'] \n",
            "\n",
            "('sets', 0.2012)  :  ['The result is a model that can be used in the future with different sets of data.'] \n",
            "\n",
            "('ai', 0.5209)  :  ['Successful machine learning algorithms can do different things, Malone wrote in a recent research brief about AI and the future of work that was co-authored by MIT professor and CSAIL director Daniela Rus and Robert Laubacher, the associate director of the MIT Center for Collective Intelligence.'] \n",
            "\n",
            "('authored', 0.428)  :  ['Successful machine learning algorithms can do different things, Malone wrote in a recent research brief about AI and the future of work that was co-authored by MIT professor and CSAIL director Daniela Rus and Robert Laubacher, the associate director of the MIT Center for Collective Intelligence.'] \n",
            "\n",
            "('algorithms', 0.3731)  :  ['Successful machine learning algorithms can do different things, Malone wrote in a recent research brief about AI and the future of work that was co-authored by MIT professor and CSAIL director Daniela Rus and Robert Laubacher, the associate director of the MIT Center for Collective Intelligence.'] \n",
            "\n",
            "('learning', 0.3651)  :  ['Successful machine learning algorithms can do different things, Malone wrote in a recent research brief about AI and the future of work that was co-authored by MIT professor and CSAIL director Daniela Rus and Robert Laubacher, the associate director of the MIT Center for Collective Intelligence.'] \n",
            "\n",
            "('intelligence', 0.36)  :  ['Successful machine learning algorithms can do different things, Malone wrote in a recent research brief about AI and the future of work that was co-authored by MIT professor and CSAIL director Daniela Rus and Robert Laubacher, the associate director of the MIT Center for Collective Intelligence.'] \n",
            "\n",
            "('predictive', 0.46)  :  ['“The function of a machine learning system can be descriptive, meaning that the system uses the data to explain what happened; predictive, meaning the system uses the data to predict what will happen; or prescriptive, meaning the system will use the data to make suggestions about what action to take,” the researchers wrote.'] \n",
            "\n",
            "('data', 0.4002)  :  ['“The function of a machine learning system can be descriptive, meaning that the system uses the data to explain what happened; predictive, meaning the system uses the data to predict what will happen; or prescriptive, meaning the system will use the data to make suggestions about what action to take,” the researchers wrote.'] \n",
            "\n",
            "('descriptive', 0.394)  :  ['“The function of a machine learning system can be descriptive, meaning that the system uses the data to explain what happened; predictive, meaning the system uses the data to predict what will happen; or prescriptive, meaning the system will use the data to make suggestions about what action to take,” the researchers wrote.'] \n",
            "\n",
            "('predict', 0.3794)  :  ['“The function of a machine learning system can be descriptive, meaning that the system uses the data to explain what happened; predictive, meaning the system uses the data to predict what will happen; or prescriptive, meaning the system will use the data to make suggestions about what action to take,” the researchers wrote.'] \n",
            "\n",
            "('learning', 0.3405)  :  ['“The function of a machine learning system can be descriptive, meaning that the system uses the data to explain what happened; predictive, meaning the system uses the data to predict what will happen; or prescriptive, meaning the system will use the data to make suggestions about what action to take,” the researchers wrote.'] \n",
            "\n",
            "('subcategories', 0.4806)  :  ['There are three subcategories of machine learning:\\n\\nSupervised machine learning models are trained with labeled data sets, which allow the models to learn and grow more accurate over time.'] \n",
            "\n",
            "('supervised', 0.4698)  :  ['There are three subcategories of machine learning:\\n\\nSupervised machine learning models are trained with labeled data sets, which allow the models to learn and grow more accurate over time.'] \n",
            "\n",
            "('labeled', 0.3257)  :  ['There are three subcategories of machine learning:\\n\\nSupervised machine learning models are trained with labeled data sets, which allow the models to learn and grow more accurate over time.'] \n",
            "\n",
            "('machine', 0.3241)  :  ['There are three subcategories of machine learning:\\n\\nSupervised machine learning models are trained with labeled data sets, which allow the models to learn and grow more accurate over time.'] \n",
            "\n",
            "('models', 0.3084)  :  ['There are three subcategories of machine learning:\\n\\nSupervised machine learning models are trained with labeled data sets, which allow the models to learn and grow more accurate over time.'] \n",
            "\n",
            "('algorithm', 0.3644)  :  ['For example, an algorithm would be trained with pictures of dogs and other things, all labeled by humans, and the machine would learn ways to identify pictures of dogs on its own.'] \n",
            "\n",
            "('trained', 0.353)  :  ['For example, an algorithm would be trained with pictures of dogs and other things, all labeled by humans, and the machine would learn ways to identify pictures of dogs on its own.'] \n",
            "\n",
            "('labeled', 0.3521)  :  ['For example, an algorithm would be trained with pictures of dogs and other things, all labeled by humans, and the machine would learn ways to identify pictures of dogs on its own.'] \n",
            "\n",
            "('machine', 0.34)  :  ['For example, an algorithm would be trained with pictures of dogs and other things, all labeled by humans, and the machine would learn ways to identify pictures of dogs on its own.'] \n",
            "\n",
            "('pictures', 0.3217)  :  ['For example, an algorithm would be trained with pictures of dogs and other things, all labeled by humans, and the machine would learn ways to identify pictures of dogs on its own.'] \n",
            "\n",
            "('supervised', 0.579)  :  ['Supervised machine learning is the most common type used today.'] \n",
            "\n",
            "('learning', 0.3551)  :  ['Supervised machine learning is the most common type used today.'] \n",
            "\n",
            "('type', 0.3468)  :  ['Supervised machine learning is the most common type used today.'] \n",
            "\n",
            "('common', 0.3393)  :  ['Supervised machine learning is the most common type used today.'] \n",
            "\n",
            "('machine', 0.2708)  :  ['Supervised machine learning is the most common type used today.'] \n",
            "\n",
            "('unlabeled', 0.5392)  :  ['In unsupervised machine learning, a program looks for patterns in unlabeled data.'] \n",
            "\n",
            "('unsupervised', 0.5312)  :  ['In unsupervised machine learning, a program looks for patterns in unlabeled data.'] \n",
            "\n",
            "('patterns', 0.5199)  :  ['In unsupervised machine learning, a program looks for patterns in unlabeled data.'] \n",
            "\n",
            "('data', 0.3497)  :  ['In unsupervised machine learning, a program looks for patterns in unlabeled data.'] \n",
            "\n",
            "('program', 0.3072)  :  ['In unsupervised machine learning, a program looks for patterns in unlabeled data.'] \n",
            "\n",
            "('unsupervised', 0.5388)  :  ['Unsupervised machine learning can find patterns or trends that people aren’t explicitly looking for.'] \n",
            "\n",
            "('trends', 0.45)  :  ['Unsupervised machine learning can find patterns or trends that people aren’t explicitly looking for.'] \n",
            "\n",
            "('patterns', 0.3984)  :  ['Unsupervised machine learning can find patterns or trends that people aren’t explicitly looking for.'] \n",
            "\n",
            "('learning', 0.3151)  :  ['Unsupervised machine learning can find patterns or trends that people aren’t explicitly looking for.'] \n",
            "\n",
            "('explicitly', 0.1744)  :  ['Unsupervised machine learning can find patterns or trends that people aren’t explicitly looking for.'] \n",
            "\n",
            "('sales', 0.4101)  :  ['For example, an unsupervised machine learning program could look through online sales data and identify different types of clients making purchases.'] \n",
            "\n",
            "('clients', 0.375)  :  ['For example, an unsupervised machine learning program could look through online sales data and identify different types of clients making purchases.'] \n",
            "\n",
            "('purchases', 0.3721)  :  ['For example, an unsupervised machine learning program could look through online sales data and identify different types of clients making purchases.'] \n",
            "\n",
            "('unsupervised', 0.3317)  :  ['For example, an unsupervised machine learning program could look through online sales data and identify different types of clients making purchases.'] \n",
            "\n",
            "('data', 0.3115)  :  ['For example, an unsupervised machine learning program could look through online sales data and identify different types of clients making purchases.'] \n",
            "\n",
            "('reinforcement', 0.5889)  :  ['Reinforcement machine learning trains machines through trial and error to take the best action by establishing a reward system.'] \n",
            "\n",
            "('reward', 0.5282)  :  ['Reinforcement machine learning trains machines through trial and error to take the best action by establishing a reward system.'] \n",
            "\n",
            "('learning', 0.452)  :  ['Reinforcement machine learning trains machines through trial and error to take the best action by establishing a reward system.'] \n",
            "\n",
            "('machines', 0.4113)  :  ['Reinforcement machine learning trains machines through trial and error to take the best action by establishing a reward system.'] \n",
            "\n",
            "('machine', 0.3766)  :  ['Reinforcement machine learning trains machines through trial and error to take the best action by establishing a reward system.'] \n",
            "\n",
            "('reinforcement', 0.5874)  :  ['Reinforcement learning can train models to play games or train autonomous vehicles to drive by telling the machine when it made the right decisions, which helps it learn over time what actions it should take.'] \n",
            "\n",
            "('autonomous', 0.4421)  :  ['Reinforcement learning can train models to play games or train autonomous vehicles to drive by telling the machine when it made the right decisions, which helps it learn over time what actions it should take.'] \n",
            "\n",
            "('learning', 0.3853)  :  ['Reinforcement learning can train models to play games or train autonomous vehicles to drive by telling the machine when it made the right decisions, which helps it learn over time what actions it should take.'] \n",
            "\n",
            "('games', 0.3137)  :  ['Reinforcement learning can train models to play games or train autonomous vehicles to drive by telling the machine when it made the right decisions, which helps it learn over time what actions it should take.'] \n",
            "\n",
            "('learn', 0.3036)  :  ['Reinforcement learning can train models to play games or train autonomous vehicles to drive by telling the machine when it made the right decisions, which helps it learn over time what actions it should take.'] \n",
            "\n",
            "('machines', 0.4132)  :  ['In the Work of the Future brief, Malone noted that machine learning is best suited for situations with lots of data — thousands or millions of examples, like recordings from previous conversations with customers, sensor logs from machines, or ATM transactions.'] \n",
            "\n",
            "('learning', 0.3772)  :  ['In the Work of the Future brief, Malone noted that machine learning is best suited for situations with lots of data — thousands or millions of examples, like recordings from previous conversations with customers, sensor logs from machines, or ATM transactions.'] \n",
            "\n",
            "('data', 0.3549)  :  ['In the Work of the Future brief, Malone noted that machine learning is best suited for situations with lots of data — thousands or millions of examples, like recordings from previous conversations with customers, sensor logs from machines, or ATM transactions.'] \n",
            "\n",
            "('machine', 0.3472)  :  ['In the Work of the Future brief, Malone noted that machine learning is best suited for situations with lots of data — thousands or millions of examples, like recordings from previous conversations with customers, sensor logs from machines, or ATM transactions.'] \n",
            "\n",
            "('recordings', 0.3052)  :  ['In the Work of the Future brief, Malone noted that machine learning is best suited for situations with lots of data — thousands or millions of examples, like recordings from previous conversations with customers, sensor logs from machines, or ATM transactions.'] \n",
            "\n",
            "('languages', 0.4272)  :  ['For example, Google Translate was possible because it “trained” on the vast amount of information on the web, in different languages.'] \n",
            "\n",
            "('google', 0.3748)  :  ['For example, Google Translate was possible because it “trained” on the vast amount of information on the web, in different languages.'] \n",
            "\n",
            "('translate', 0.3262)  :  ['For example, Google Translate was possible because it “trained” on the vast amount of information on the web, in different languages.'] \n",
            "\n",
            "('web', 0.3091)  :  ['For example, Google Translate was possible because it “trained” on the vast amount of information on the web, in different languages.'] \n",
            "\n",
            "('trained', 0.2451)  :  ['For example, Google Translate was possible because it “trained” on the vast amount of information on the web, in different languages.'] \n",
            "\n",
            "('learning', 0.4384)  :  ['In some cases, machine learning can gain insight or automate decision-making in cases where humans would not be able to, Madry said.'] \n",
            "\n",
            "('automate', 0.4249)  :  ['In some cases, machine learning can gain insight or automate decision-making in cases where humans would not be able to, Madry said.'] \n",
            "\n",
            "('insight', 0.3614)  :  ['In some cases, machine learning can gain insight or automate decision-making in cases where humans would not be able to, Madry said.'] \n",
            "\n",
            "('machine', 0.2698)  :  ['In some cases, machine learning can gain insight or automate decision-making in cases where humans would not be able to, Madry said.'] \n",
            "\n",
            "('decision', 0.259)  :  ['In some cases, machine learning can gain insight or automate decision-making in cases where humans would not be able to, Madry said.'] \n",
            "\n",
            "('algorithm', 0.4519)  :  ['“It may not only be more efficient and less costly to have an algorithm do this, but sometimes humans just literally are not able to do it,” he said.'] \n",
            "\n",
            "('efficient', 0.3505)  :  ['“It may not only be more efficient and less costly to have an algorithm do this, but sometimes humans just literally are not able to do it,” he said.'] \n",
            "\n",
            "('costly', 0.1992)  :  ['“It may not only be more efficient and less costly to have an algorithm do this, but sometimes humans just literally are not able to do it,” he said.'] \n",
            "\n",
            "('humans', 0.1488)  :  ['“It may not only be more efficient and less costly to have an algorithm do this, but sometimes humans just literally are not able to do it,” he said.'] \n",
            "\n",
            "('literally', 0.1293)  :  ['“It may not only be more efficient and less costly to have an algorithm do this, but sometimes humans just literally are not able to do it,” he said.'] \n",
            "\n",
            "('google', 0.4715)  :  ['Google search is an example of something that humans can do, but never at the scale and speed at which the Google models are able to show potential answers every time a person types in a query, Malone said.'] \n",
            "\n",
            "('search', 0.4655)  :  ['Google search is an example of something that humans can do, but never at the scale and speed at which the Google models are able to show potential answers every time a person types in a query, Malone said.'] \n",
            "\n",
            "('answers', 0.3082)  :  ['Google search is an example of something that humans can do, but never at the scale and speed at which the Google models are able to show potential answers every time a person types in a query, Malone said.'] \n",
            "\n",
            "('models', 0.2918)  :  ['Google search is an example of something that humans can do, but never at the scale and speed at which the Google models are able to show potential answers every time a person types in a query, Malone said.'] \n",
            "\n",
            "('example', 0.291)  :  ['Google search is an example of something that humans can do, but never at the scale and speed at which the Google models are able to show potential answers every time a person types in a query, Malone said.'] \n",
            "\n",
            "('computers', 0.4685)  :  ['“That’s not an example of computers putting people out of work.'] \n",
            "\n",
            "('example', 0.348)  :  ['“That’s not an example of computers putting people out of work.'] \n",
            "\n",
            "('work', 0.2918)  :  ['“That’s not an example of computers putting people out of work.'] \n",
            "\n",
            "('people', 0.1779)  :  ['“That’s not an example of computers putting people out of work.'] \n",
            "\n",
            "('putting', 0.1313)  :  ['“That’s not an example of computers putting people out of work.'] \n",
            "\n",
            "('machines', 0.4494)  :  [\"It's an example of computers doing things that would not have been remotely economically feasible if they had to be done by humans.”\\n\\nMachine learning is also associated with several other artificial intelligence subfields:\\n\\nNatural language processing\\n\\nNatural language processing is a field of machine learning in which machines learn to understand natural language as spoken and written by humans, instead of the data and numbers normally used to program computers.\"] \n",
            "\n",
            "('computers', 0.4103)  :  [\"It's an example of computers doing things that would not have been remotely economically feasible if they had to be done by humans.”\\n\\nMachine learning is also associated with several other artificial intelligence subfields:\\n\\nNatural language processing\\n\\nNatural language processing is a field of machine learning in which machines learn to understand natural language as spoken and written by humans, instead of the data and numbers normally used to program computers.\"] \n",
            "\n",
            "('machine', 0.3611)  :  [\"It's an example of computers doing things that would not have been remotely economically feasible if they had to be done by humans.”\\n\\nMachine learning is also associated with several other artificial intelligence subfields:\\n\\nNatural language processing\\n\\nNatural language processing is a field of machine learning in which machines learn to understand natural language as spoken and written by humans, instead of the data and numbers normally used to program computers.\"] \n",
            "\n",
            "('learning', 0.3598)  :  [\"It's an example of computers doing things that would not have been remotely economically feasible if they had to be done by humans.”\\n\\nMachine learning is also associated with several other artificial intelligence subfields:\\n\\nNatural language processing\\n\\nNatural language processing is a field of machine learning in which machines learn to understand natural language as spoken and written by humans, instead of the data and numbers normally used to program computers.\"] \n",
            "\n",
            "('artificial', 0.3399)  :  [\"It's an example of computers doing things that would not have been remotely economically feasible if they had to be done by humans.”\\n\\nMachine learning is also associated with several other artificial intelligence subfields:\\n\\nNatural language processing\\n\\nNatural language processing is a field of machine learning in which machines learn to understand natural language as spoken and written by humans, instead of the data and numbers normally used to program computers.\"] \n",
            "\n",
            "('language', 0.5223)  :  ['This allows machines to recognize language, understand it, and respond to it, as well as create new text and translate between languages.'] \n",
            "\n",
            "('languages', 0.506)  :  ['This allows machines to recognize language, understand it, and respond to it, as well as create new text and translate between languages.'] \n",
            "\n",
            "('text', 0.445)  :  ['This allows machines to recognize language, understand it, and respond to it, as well as create new text and translate between languages.'] \n",
            "\n",
            "('machines', 0.4311)  :  ['This allows machines to recognize language, understand it, and respond to it, as well as create new text and translate between languages.'] \n",
            "\n",
            "('translate', 0.3306)  :  ['This allows machines to recognize language, understand it, and respond to it, as well as create new text and translate between languages.'] \n",
            "\n",
            "('chatbots', 0.5862)  :  ['Natural language processing enables familiar technology like chatbots and digital assistants like Siri or Alexa.'] \n",
            "\n",
            "('alexa', 0.4289)  :  ['Natural language processing enables familiar technology like chatbots and digital assistants like Siri or Alexa.'] \n",
            "\n",
            "('processing', 0.3767)  :  ['Natural language processing enables familiar technology like chatbots and digital assistants like Siri or Alexa.'] \n",
            "\n",
            "('language', 0.361)  :  ['Natural language processing enables familiar technology like chatbots and digital assistants like Siri or Alexa.'] \n",
            "\n",
            "('siri', 0.3395)  :  ['Natural language processing enables familiar technology like chatbots and digital assistants like Siri or Alexa.'] \n",
            "\n",
            "('algorithms', 0.4424)  :  ['Neural networks\\n\\nNeural networks are a commonly used, specific class of machine learning algorithms.'] \n",
            "\n",
            "('neural', 0.4106)  :  ['Neural networks\\n\\nNeural networks are a commonly used, specific class of machine learning algorithms.'] \n",
            "\n",
            "('networks', 0.3985)  :  ['Neural networks\\n\\nNeural networks are a commonly used, specific class of machine learning algorithms.'] \n",
            "\n",
            "('learning', 0.3304)  :  ['Neural networks\\n\\nNeural networks are a commonly used, specific class of machine learning algorithms.'] \n",
            "\n",
            "('machine', 0.2348)  :  ['Neural networks\\n\\nNeural networks are a commonly used, specific class of machine learning algorithms.'] \n",
            "\n",
            "('neural', 0.5783)  :  ['Artificial neural networks are modeled on the human brain, in which thousands or millions of processing nodes are interconnected and organized into layers.'] \n",
            "\n",
            "('networks', 0.4684)  :  ['Artificial neural networks are modeled on the human brain, in which thousands or millions of processing nodes are interconnected and organized into layers.'] \n",
            "\n",
            "('brain', 0.4394)  :  ['Artificial neural networks are modeled on the human brain, in which thousands or millions of processing nodes are interconnected and organized into layers.'] \n",
            "\n",
            "('layers', 0.3964)  :  ['Artificial neural networks are modeled on the human brain, in which thousands or millions of processing nodes are interconnected and organized into layers.'] \n",
            "\n",
            "('nodes', 0.3495)  :  ['Artificial neural networks are modeled on the human brain, in which thousands or millions of processing nodes are interconnected and organized into layers.'] \n",
            "\n",
            "('neurons', 0.5888)  :  ['In an artificial neural network, cells, or nodes, are connected, with each cell processing inputs and producing an output that is sent to other neurons.'] \n",
            "\n",
            "('neural', 0.5423)  :  ['In an artificial neural network, cells, or nodes, are connected, with each cell processing inputs and producing an output that is sent to other neurons.'] \n",
            "\n",
            "('nodes', 0.4903)  :  ['In an artificial neural network, cells, or nodes, are connected, with each cell processing inputs and producing an output that is sent to other neurons.'] \n",
            "\n",
            "('network', 0.4102)  :  ['In an artificial neural network, cells, or nodes, are connected, with each cell processing inputs and producing an output that is sent to other neurons.'] \n",
            "\n",
            "('cells', 0.3995)  :  ['In an artificial neural network, cells, or nodes, are connected, with each cell processing inputs and producing an output that is sent to other neurons.'] \n",
            "\n",
            "('labeled', 0.5004)  :  ['Labeled data moves through the nodes, or cells, with each cell performing a different function.'] \n",
            "\n",
            "('cells', 0.4891)  :  ['Labeled data moves through the nodes, or cells, with each cell performing a different function.'] \n",
            "\n",
            "('nodes', 0.4861)  :  ['Labeled data moves through the nodes, or cells, with each cell performing a different function.'] \n",
            "\n",
            "('cell', 0.4681)  :  ['Labeled data moves through the nodes, or cells, with each cell performing a different function.'] \n",
            "\n",
            "('data', 0.4117)  :  ['Labeled data moves through the nodes, or cells, with each cell performing a different function.'] \n",
            "\n",
            "('neural', 0.493)  :  ['In a neural network trained to identify whether a picture contains a cat or not, the different nodes would assess the information and arrive at an output that indicates whether a picture features a cat.'] \n",
            "\n",
            "('cat', 0.4272)  :  ['In a neural network trained to identify whether a picture contains a cat or not, the different nodes would assess the information and arrive at an output that indicates whether a picture features a cat.'] \n",
            "\n",
            "('nodes', 0.3208)  :  ['In a neural network trained to identify whether a picture contains a cat or not, the different nodes would assess the information and arrive at an output that indicates whether a picture features a cat.'] \n",
            "\n",
            "('network', 0.3111)  :  ['In a neural network trained to identify whether a picture contains a cat or not, the different nodes would assess the information and arrive at an output that indicates whether a picture features a cat.'] \n",
            "\n",
            "('trained', 0.3031)  :  ['In a neural network trained to identify whether a picture contains a cat or not, the different nodes would assess the information and arrive at an output that indicates whether a picture features a cat.'] \n",
            "\n",
            "('layers', 0.443)  :  ['Deep learning\\n\\nDeep learning networks are neural networks with many layers.'] \n",
            "\n",
            "('networks', 0.4377)  :  ['Deep learning\\n\\nDeep learning networks are neural networks with many layers.'] \n",
            "\n",
            "('neural', 0.4346)  :  ['Deep learning\\n\\nDeep learning networks are neural networks with many layers.'] \n",
            "\n",
            "('deep', 0.3869)  :  ['Deep learning\\n\\nDeep learning networks are neural networks with many layers.'] \n",
            "\n",
            "('learning', 0.3745)  :  ['Deep learning\\n\\nDeep learning networks are neural networks with many layers.'] \n",
            "\n",
            "('layers', 0.5371)  :  ['The layered network can process extensive amounts of data and determine the “weight” of each link in the network — for example, in an image recognition system, some layers of the neural network might detect individual features of a face, like eyes, nose, or mouth, while another layer would be able to tell whether those features appear in a way that indicates a face.'] \n",
            "\n",
            "('layer', 0.5057)  :  ['The layered network can process extensive amounts of data and determine the “weight” of each link in the network — for example, in an image recognition system, some layers of the neural network might detect individual features of a face, like eyes, nose, or mouth, while another layer would be able to tell whether those features appear in a way that indicates a face.'] \n",
            "\n",
            "('layered', 0.4866)  :  ['The layered network can process extensive amounts of data and determine the “weight” of each link in the network — for example, in an image recognition system, some layers of the neural network might detect individual features of a face, like eyes, nose, or mouth, while another layer would be able to tell whether those features appear in a way that indicates a face.'] \n",
            "\n",
            "('recognition', 0.4307)  :  ['The layered network can process extensive amounts of data and determine the “weight” of each link in the network — for example, in an image recognition system, some layers of the neural network might detect individual features of a face, like eyes, nose, or mouth, while another layer would be able to tell whether those features appear in a way that indicates a face.'] \n",
            "\n",
            "('neural', 0.414)  :  ['The layered network can process extensive amounts of data and determine the “weight” of each link in the network — for example, in an image recognition system, some layers of the neural network might detect individual features of a face, like eyes, nose, or mouth, while another layer would be able to tell whether those features appear in a way that indicates a face.'] \n",
            "\n",
            "('neural', 0.4801)  :  ['Like neural networks, deep learning is modeled on the way the human brain works and powers many machine learning uses, like autonomous vehicles, chatbots, and medical diagnostics.'] \n",
            "\n",
            "('deep', 0.351)  :  ['Like neural networks, deep learning is modeled on the way the human brain works and powers many machine learning uses, like autonomous vehicles, chatbots, and medical diagnostics.'] \n",
            "\n",
            "('networks', 0.3393)  :  ['Like neural networks, deep learning is modeled on the way the human brain works and powers many machine learning uses, like autonomous vehicles, chatbots, and medical diagnostics.'] \n",
            "\n",
            "('learning', 0.3334)  :  ['Like neural networks, deep learning is modeled on the way the human brain works and powers many machine learning uses, like autonomous vehicles, chatbots, and medical diagnostics.'] \n",
            "\n",
            "('brain', 0.3149)  :  ['Like neural networks, deep learning is modeled on the way the human brain works and powers many machine learning uses, like autonomous vehicles, chatbots, and medical diagnostics.'] \n",
            "\n",
            "('layers', 0.4908)  :  ['“The more layers you have, the more potential you have for doing complex things well,” Malone said.'] \n",
            "\n",
            "('potential', 0.4593)  :  ['“The more layers you have, the more potential you have for doing complex things well,” Malone said.'] \n",
            "\n",
            "('complex', 0.3915)  :  ['“The more layers you have, the more potential you have for doing complex things well,” Malone said.'] \n",
            "\n",
            "('malone', 0.3294)  :  ['“The more layers you have, the more potential you have for doing complex things well,” Malone said.'] \n",
            "\n",
            "('said', 0.2798)  :  ['“The more layers you have, the more potential you have for doing complex things well,” Malone said.'] \n",
            "\n",
            "('computing', 0.3452)  :  ['Deep learning requires a great deal of computing power, which raises concerns about its economic and environmental sustainability.'] \n",
            "\n",
            "('learning', 0.3447)  :  ['Deep learning requires a great deal of computing power, which raises concerns about its economic and environmental sustainability.'] \n",
            "\n",
            "('deep', 0.3336)  :  ['Deep learning requires a great deal of computing power, which raises concerns about its economic and environmental sustainability.'] \n",
            "\n",
            "('power', 0.3013)  :  ['Deep learning requires a great deal of computing power, which raises concerns about its economic and environmental sustainability.'] \n",
            "\n",
            "('sustainability', 0.3)  :  ['Deep learning requires a great deal of computing power, which raises concerns about its economic and environmental sustainability.'] \n",
            "\n",
            "('businesses', 0.4351)  :  ['How businesses are using machine learning\\nMachine learning is the core of some companies’ business models, like in the case of Netflix’s suggestions algorithm or Google’s search engine.'] \n",
            "\n",
            "('companies', 0.3729)  :  ['How businesses are using machine learning\\nMachine learning is the core of some companies’ business models, like in the case of Netflix’s suggestions algorithm or Google’s search engine.'] \n",
            "\n",
            "('business', 0.3638)  :  ['How businesses are using machine learning\\nMachine learning is the core of some companies’ business models, like in the case of Netflix’s suggestions algorithm or Google’s search engine.'] \n",
            "\n",
            "('learning', 0.346)  :  ['How businesses are using machine learning\\nMachine learning is the core of some companies’ business models, like in the case of Netflix’s suggestions algorithm or Google’s search engine.'] \n",
            "\n",
            "('google', 0.3352)  :  ['How businesses are using machine learning\\nMachine learning is the core of some companies’ business models, like in the case of Netflix’s suggestions algorithm or Google’s search engine.'] \n",
            "\n",
            "('companies', 0.4142)  :  ['Other companies are engaging deeply with machine learning, though it’s not their main business proposition.'] \n",
            "\n",
            "('learning', 0.3868)  :  ['Other companies are engaging deeply with machine learning, though it’s not their main business proposition.'] \n",
            "\n",
            "('business', 0.3097)  :  ['Other companies are engaging deeply with machine learning, though it’s not their main business proposition.'] \n",
            "\n",
            "('machine', 0.2663)  :  ['Other companies are engaging deeply with machine learning, though it’s not their main business proposition.'] \n",
            "\n",
            "('engaging', 0.2512)  :  ['Other companies are engaging deeply with machine learning, though it’s not their main business proposition.'] \n",
            "\n",
            "('learning', 0.4636)  :  ['Others are still trying to determine how to use machine learning in a beneficial way.'] \n",
            "\n",
            "('beneficial', 0.2942)  :  ['Others are still trying to determine how to use machine learning in a beneficial way.'] \n",
            "\n",
            "('machine', 0.2847)  :  ['Others are still trying to determine how to use machine learning in a beneficial way.'] \n",
            "\n",
            "('use', 0.2357)  :  ['Others are still trying to determine how to use machine learning in a beneficial way.'] \n",
            "\n",
            "('determine', 0.2218)  :  ['Others are still trying to determine how to use machine learning in a beneficial way.'] \n",
            "\n",
            "('learning', 0.4407)  :  ['“In my opinion, one of the hardest problems in machine learning is figuring out what problems I can solve with machine learning,” Shulman said.'] \n",
            "\n",
            "('hardest', 0.3713)  :  ['“In my opinion, one of the hardest problems in machine learning is figuring out what problems I can solve with machine learning,” Shulman said.'] \n",
            "\n",
            "('problems', 0.3453)  :  ['“In my opinion, one of the hardest problems in machine learning is figuring out what problems I can solve with machine learning,” Shulman said.'] \n",
            "\n",
            "('shulman', 0.2859)  :  ['“In my opinion, one of the hardest problems in machine learning is figuring out what problems I can solve with machine learning,” Shulman said.'] \n",
            "\n",
            "('machine', 0.2576)  :  ['“In my opinion, one of the hardest problems in machine learning is figuring out what problems I can solve with machine learning,” Shulman said.'] \n",
            "\n",
            "('learning', 0.4158)  :  ['“There’s still a gap in the understanding.” \\n\\nIn a 2018 paper, researchers from the MIT Initiative on the Digital Economy outlined a 21-question rubric to determine whether a task is suitable for machine learning.'] \n",
            "\n",
            "('rubric', 0.3376)  :  ['“There’s still a gap in the understanding.” \\n\\nIn a 2018 paper, researchers from the MIT Initiative on the Digital Economy outlined a 21-question rubric to determine whether a task is suitable for machine learning.'] \n",
            "\n",
            "('machine', 0.3007)  :  ['“There’s still a gap in the understanding.” \\n\\nIn a 2018 paper, researchers from the MIT Initiative on the Digital Economy outlined a 21-question rubric to determine whether a task is suitable for machine learning.'] \n",
            "\n",
            "('task', 0.2992)  :  ['“There’s still a gap in the understanding.” \\n\\nIn a 2018 paper, researchers from the MIT Initiative on the Digital Economy outlined a 21-question rubric to determine whether a task is suitable for machine learning.'] \n",
            "\n",
            "('digital', 0.2823)  :  ['“There’s still a gap in the understanding.” \\n\\nIn a 2018 paper, researchers from the MIT Initiative on the Digital Economy outlined a 21-question rubric to determine whether a task is suitable for machine learning.'] \n",
            "\n",
            "('occupation', 0.414)  :  ['The researchers found that no occupation will be untouched by machine learning, but no occupation is likely to be completely taken over by it.'] \n",
            "\n",
            "('learning', 0.2466)  :  ['The researchers found that no occupation will be untouched by machine learning, but no occupation is likely to be completely taken over by it.'] \n",
            "\n",
            "('untouched', 0.2135)  :  ['The researchers found that no occupation will be untouched by machine learning, but no occupation is likely to be completely taken over by it.'] \n",
            "\n",
            "('completely', 0.21)  :  ['The researchers found that no occupation will be untouched by machine learning, but no occupation is likely to be completely taken over by it.'] \n",
            "\n",
            "('researchers', 0.2096)  :  ['The researchers found that no occupation will be untouched by machine learning, but no occupation is likely to be completely taken over by it.'] \n",
            "\n",
            "('jobs', 0.4345)  :  ['The way to unleash machine learning success, the researchers found, was to reorganize jobs into discrete tasks, some which can be done by machine learning, and others that require a human.'] \n",
            "\n",
            "('learning', 0.4206)  :  ['The way to unleash machine learning success, the researchers found, was to reorganize jobs into discrete tasks, some which can be done by machine learning, and others that require a human.'] \n",
            "\n",
            "('tasks', 0.42)  :  ['The way to unleash machine learning success, the researchers found, was to reorganize jobs into discrete tasks, some which can be done by machine learning, and others that require a human.'] \n",
            "\n",
            "('machine', 0.3383)  :  ['The way to unleash machine learning success, the researchers found, was to reorganize jobs into discrete tasks, some which can be done by machine learning, and others that require a human.'] \n",
            "\n",
            "('reorganize', 0.3187)  :  ['The way to unleash machine learning success, the researchers found, was to reorganize jobs into discrete tasks, some which can be done by machine learning, and others that require a human.'] \n",
            "\n",
            "('recommendation', 0.3872)  :  ['Companies are already using machine learning in several ways, including:\\n\\nRecommendation algorithms.'] \n",
            "\n",
            "('algorithms', 0.3606)  :  ['Companies are already using machine learning in several ways, including:\\n\\nRecommendation algorithms.'] \n",
            "\n",
            "('companies', 0.3572)  :  ['Companies are already using machine learning in several ways, including:\\n\\nRecommendation algorithms.'] \n",
            "\n",
            "('learning', 0.3067)  :  ['Companies are already using machine learning in several ways, including:\\n\\nRecommendation algorithms.'] \n",
            "\n",
            "('machine', 0.2633)  :  ['Companies are already using machine learning in several ways, including:\\n\\nRecommendation algorithms.'] \n",
            "\n",
            "('netflix', 0.4234)  :  ['The recommendation engines behind Netflix and YouTube suggestions, what information appears on your Facebook feed, and product recommendations are fueled by machine learning.'] \n",
            "\n",
            "('recommendations', 0.3899)  :  ['The recommendation engines behind Netflix and YouTube suggestions, what information appears on your Facebook feed, and product recommendations are fueled by machine learning.'] \n",
            "\n",
            "('recommendation', 0.3864)  :  ['The recommendation engines behind Netflix and YouTube suggestions, what information appears on your Facebook feed, and product recommendations are fueled by machine learning.'] \n",
            "\n",
            "('youtube', 0.3861)  :  ['The recommendation engines behind Netflix and YouTube suggestions, what information appears on your Facebook feed, and product recommendations are fueled by machine learning.'] \n",
            "\n",
            "('facebook', 0.3693)  :  ['The recommendation engines behind Netflix and YouTube suggestions, what information appears on your Facebook feed, and product recommendations are fueled by machine learning.'] \n",
            "\n",
            "('algorithms', 0.4556)  :  ['“[The algorithms] are trying to learn our preferences,” Madry said.'] \n",
            "\n",
            "('madry', 0.3921)  :  ['“[The algorithms] are trying to learn our preferences,” Madry said.'] \n",
            "\n",
            "('preferences', 0.3452)  :  ['“[The algorithms] are trying to learn our preferences,” Madry said.'] \n",
            "\n",
            "('learn', 0.3063)  :  ['“[The algorithms] are trying to learn our preferences,” Madry said.'] \n",
            "\n",
            "('said', 0.2088)  :  ['“[The algorithms] are trying to learn our preferences,” Madry said.'] \n",
            "\n",
            "('tweets', 0.5775)  :  ['“They want to learn, like on Twitter, what tweets we want them to show us, on Facebook, what ads to display, what posts or liked content to share with us.”\\n\\nImage analysis and object detection.'] \n",
            "\n",
            "('twitter', 0.5198)  :  ['“They want to learn, like on Twitter, what tweets we want them to show us, on Facebook, what ads to display, what posts or liked content to share with us.”\\n\\nImage analysis and object detection.'] \n",
            "\n",
            "('facebook', 0.513)  :  ['“They want to learn, like on Twitter, what tweets we want them to show us, on Facebook, what ads to display, what posts or liked content to share with us.”\\n\\nImage analysis and object detection.'] \n",
            "\n",
            "('detection', 0.4026)  :  ['“They want to learn, like on Twitter, what tweets we want them to show us, on Facebook, what ads to display, what posts or liked content to share with us.”\\n\\nImage analysis and object detection.'] \n",
            "\n",
            "('content', 0.391)  :  ['“They want to learn, like on Twitter, what tweets we want them to show us, on Facebook, what ads to display, what posts or liked content to share with us.”\\n\\nImage analysis and object detection.'] \n",
            "\n",
            "('recognition', 0.5212)  :  ['Machine learning can analyze images for different information, like learning to identify people and tell them apart — though facial recognition algorithms are controversial.'] \n",
            "\n",
            "('facial', 0.3845)  :  ['Machine learning can analyze images for different information, like learning to identify people and tell them apart — though facial recognition algorithms are controversial.'] \n",
            "\n",
            "('images', 0.3712)  :  ['Machine learning can analyze images for different information, like learning to identify people and tell them apart — though facial recognition algorithms are controversial.'] \n",
            "\n",
            "('learning', 0.3513)  :  ['Machine learning can analyze images for different information, like learning to identify people and tell them apart — though facial recognition algorithms are controversial.'] \n",
            "\n",
            "('algorithms', 0.3455)  :  ['Machine learning can analyze images for different information, like learning to identify people and tell them apart — though facial recognition algorithms are controversial.'] \n",
            "\n",
            "('uses', 0.4657)  :  ['Business uses for this vary.'] \n",
            "\n",
            "('vary', 0.4454)  :  ['Business uses for this vary.'] \n",
            "\n",
            "('business', 0.3992)  :  ['Business uses for this vary.'] \n",
            "\n",
            "('learning', 0.4362)  :  ['Shulman noted that hedge funds famously use machine learning to analyze the number of cars in parking lots, which helps them learn how companies are performing and make good bets.'] \n",
            "\n",
            "('hedge', 0.3996)  :  ['Shulman noted that hedge funds famously use machine learning to analyze the number of cars in parking lots, which helps them learn how companies are performing and make good bets.'] \n",
            "\n",
            "('parking', 0.315)  :  ['Shulman noted that hedge funds famously use machine learning to analyze the number of cars in parking lots, which helps them learn how companies are performing and make good bets.'] \n",
            "\n",
            "('learn', 0.2943)  :  ['Shulman noted that hedge funds famously use machine learning to analyze the number of cars in parking lots, which helps them learn how companies are performing and make good bets.'] \n",
            "\n",
            "('cars', 0.294)  :  ['Shulman noted that hedge funds famously use machine learning to analyze the number of cars in parking lots, which helps them learn how companies are performing and make good bets.'] \n",
            "\n",
            "('fraud', 0.7722)  :  ['Fraud detection.'] \n",
            "\n",
            "('detection', 0.4777)  :  ['Fraud detection.'] \n",
            "\n",
            "('machines', 0.4567)  :  ['Machines can analyze patterns, like how someone normally spends or where they normally shop, to identify potentially fraudulent credit card transactions, log-in attempts, or spam emails.'] \n",
            "\n",
            "('patterns', 0.4181)  :  ['Machines can analyze patterns, like how someone normally spends or where they normally shop, to identify potentially fraudulent credit card transactions, log-in attempts, or spam emails.'] \n",
            "\n",
            "('transactions', 0.3991)  :  ['Machines can analyze patterns, like how someone normally spends or where they normally shop, to identify potentially fraudulent credit card transactions, log-in attempts, or spam emails.'] \n",
            "\n",
            "('analyze', 0.3616)  :  ['Machines can analyze patterns, like how someone normally spends or where they normally shop, to identify potentially fraudulent credit card transactions, log-in attempts, or spam emails.'] \n",
            "\n",
            "('fraudulent', 0.3443)  :  ['Machines can analyze patterns, like how someone normally spends or where they normally shop, to identify potentially fraudulent credit card transactions, log-in attempts, or spam emails.'] \n",
            "\n",
            "('chatbots', 0.6978)  :  ['Automatic helplines or chatbots.'] \n",
            "\n",
            "('helplines', 0.6083)  :  ['Automatic helplines or chatbots.'] \n",
            "\n",
            "('automatic', 0.3533)  :  ['Automatic helplines or chatbots.'] \n",
            "\n",
            "('chatbots', 0.7652)  :  ['Many companies are deploying online chatbots, in which customers or clients don’t speak to humans, but instead interact with a machine.'] \n",
            "\n",
            "('interact', 0.3923)  :  ['Many companies are deploying online chatbots, in which customers or clients don’t speak to humans, but instead interact with a machine.'] \n",
            "\n",
            "('clients', 0.3443)  :  ['Many companies are deploying online chatbots, in which customers or clients don’t speak to humans, but instead interact with a machine.'] \n",
            "\n",
            "('machine', 0.2977)  :  ['Many companies are deploying online chatbots, in which customers or clients don’t speak to humans, but instead interact with a machine.'] \n",
            "\n",
            "('speak', 0.2862)  :  ['Many companies are deploying online chatbots, in which customers or clients don’t speak to humans, but instead interact with a machine.'] \n",
            "\n",
            "('bots', 0.4628)  :  ['These algorithms use machine learning and natural language processing, with the bots learning from records of past conversations to come up with appropriate responses.'] \n",
            "\n",
            "('conversations', 0.4456)  :  ['These algorithms use machine learning and natural language processing, with the bots learning from records of past conversations to come up with appropriate responses.'] \n",
            "\n",
            "('algorithms', 0.3924)  :  ['These algorithms use machine learning and natural language processing, with the bots learning from records of past conversations to come up with appropriate responses.'] \n",
            "\n",
            "('learning', 0.3417)  :  ['These algorithms use machine learning and natural language processing, with the bots learning from records of past conversations to come up with appropriate responses.'] \n",
            "\n",
            "('processing', 0.3262)  :  ['These algorithms use machine learning and natural language processing, with the bots learning from records of past conversations to come up with appropriate responses.'] \n",
            "\n",
            "('cars', 0.7321)  :  ['Self-driving cars.'] \n",
            "\n",
            "('driving', 0.6631)  :  ['Self-driving cars.'] \n",
            "\n",
            "('self', 0.51)  :  ['Self-driving cars.'] \n",
            "\n",
            "('cars', 0.3741)  :  ['Much of the technology behind self-driving cars is based on machine learning, deep learning in particular.'] \n",
            "\n",
            "('driving', 0.3665)  :  ['Much of the technology behind self-driving cars is based on machine learning, deep learning in particular.'] \n",
            "\n",
            "('learning', 0.3035)  :  ['Much of the technology behind self-driving cars is based on machine learning, deep learning in particular.'] \n",
            "\n",
            "('technology', 0.2475)  :  ['Much of the technology behind self-driving cars is based on machine learning, deep learning in particular.'] \n",
            "\n",
            "('deep', 0.2339)  :  ['Much of the technology behind self-driving cars is based on machine learning, deep learning in particular.'] \n",
            "\n",
            "('imaging', 0.7261)  :  ['Medical imaging and diagnostics.'] \n",
            "\n",
            "('diagnostics', 0.6275)  :  ['Medical imaging and diagnostics.'] \n",
            "\n",
            "('medical', 0.483)  :  ['Medical imaging and diagnostics.'] \n",
            "\n",
            "('mammogram', 0.4997)  :  ['Machine learning programs can be trained to examine medical images or other information and look for certain markers of illness, like a tool that can predict cancer risk based on a mammogram.'] \n",
            "\n",
            "('cancer', 0.3854)  :  ['Machine learning programs can be trained to examine medical images or other information and look for certain markers of illness, like a tool that can predict cancer risk based on a mammogram.'] \n",
            "\n",
            "('learning', 0.3247)  :  ['Machine learning programs can be trained to examine medical images or other information and look for certain markers of illness, like a tool that can predict cancer risk based on a mammogram.'] \n",
            "\n",
            "('images', 0.2902)  :  ['Machine learning programs can be trained to examine medical images or other information and look for certain markers of illness, like a tool that can predict cancer risk based on a mammogram.'] \n",
            "\n",
            "('programs', 0.2537)  :  ['Machine learning programs can be trained to examine medical images or other information and look for certain markers of illness, like a tool that can predict cancer risk based on a mammogram.'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Distractors with BERT"
      ],
      "metadata": {
        "id": "TTzQ5f97zG__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load BERT model\n",
        "from transformers import pipeline\n",
        "unmasker = pipeline('fill-mask', model='distilbert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "409c4bcfab3c4169bfc540626a458d04",
            "179a4fd505aa4c909766ed1681de6d94",
            "ade86601398c40238f50a7128c28dc43",
            "8a93af55ac6c425ca0b8f98e682bf961",
            "5f0df84f40a84c7abb2992d7892e9a57",
            "9216012842d84e969149c9e043103062",
            "47c29eb53cb844569c7631d634144473",
            "f859151451d9426ebbbe3f2ba20c588e",
            "8f74fd8a9bc445169b0d2f62510126c4",
            "0dddcf8a26384256affda11429852aa6",
            "f5c81ad33fb64325a78913daba62350b",
            "3e574334a1fe402e9bfa65e5acf8b732",
            "88566740eaaf482488396705a2aa2301",
            "ecd595a153014b4eaaea0273eb55956a",
            "6a838e75bbb14f6a9b3a175d2f7a7acc",
            "e7ed74d2c8674b988640eb4e38b80bc5",
            "71b984d6e421432bb3d79d8e81ad16be",
            "493dcf7dabe842379bede9ab50d22e40",
            "9049999b987b463099dbe0223d59ee69",
            "59974f7cd12648b0bef836ded25b4903",
            "2551058343c5474eb2a687b087ad7ef1",
            "981d95d8ca4c46deaa3534e5cd1abe38",
            "acf38f4614584684b3f72c9417a73b61",
            "a9403f33e6304297a4fcb929f8eb69c5",
            "bc4cf032724b4688abf274ff09cab87d",
            "77464fd2574544fb95521b8c6a9e2b5e",
            "41ac03a99b084fdf9dc083990b90caf7",
            "2d0464303f214b0c82a30f824cc2df2f",
            "f6dd6a65dd1046f58dcaf6008da3eb9a",
            "d0d4a6f78e114382a2368f9a08b70610",
            "102d060a6e9d4bd6bc1b084eddd0b47a",
            "e0f00b89ed72456bb7c9fe68d7d0a989",
            "8170101e4d104d94872f58698c2895f7",
            "f045566a71de402b8c86a1a740e1b6e5",
            "92f010bb4b6b4da5a8ee7b2f051360df",
            "461e97cb566d4e299f8d53ccbaa75ce2",
            "272fef320d9044208d9758911477513e",
            "cd20e7e38b284278bb7b9df8eb81642d",
            "a3619a268811434db81542d158a56361",
            "79c40009ef164be48e5b0df62de8f242",
            "5e7606c758a8412db93b236faaa90470",
            "235638708475445dae81299905ec280f",
            "a717b7ade95f4da894829652611ed354",
            "57abad856f7948eaa37a3c0f1eda5a30",
            "b762aaf1ac7d43418413f7fe5eedcc29",
            "84d60e77aba643b98e3230bdd377673f",
            "cb86e282268b427b881b1f8083c78403",
            "33338fe80a7941c582760b5f6bef1c08",
            "f9721f70a3c14fff98fadd428b92bf00",
            "78811c58b38d483983b9dc8feffe06db",
            "9d90621601f44009ad25e5614a6ba27a",
            "ef55071cb72c4510a45b9370ea6490e6",
            "6268f3c2d2664dc289db2e8e510e3546",
            "99742f4c78ba46c8831b4b05ee5c6830",
            "0feeaa116e0f469b8c1a12f7b436470b"
          ]
        },
        "id": "7uo5NEMvPQPC",
        "outputId": "6f46543b-c702-4f60-97cf-8e8e1fff12c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "409c4bcfab3c4169bfc540626a458d04",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e574334a1fe402e9bfa65e5acf8b732",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acf38f4614584684b3f72c9417a73b61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f045566a71de402b8c86a1a740e1b6e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b762aaf1ac7d43418413f7fe5eedcc29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def get_questions(keyword_to_sentences_map, model, k=5):\n",
        "    \"\"\"\"\n",
        "    Generates questions along with distractors\n",
        "    @input keyword_to_sentences_map : maps keywords to sentences they appear in\n",
        "    @model: BERT model that will be used to mask the keyword and generate distractors\n",
        "    @k (default 5), number of questions to return\n",
        "    \"\"\"\n",
        "\n",
        "    # we can choose answer keys randomly from the pool of keywords\n",
        "    keys = random.choices( list(keyword_to_sentences_map.keys()), k=k)\n",
        "\n",
        "    for word in keys:\n",
        "        answer = word\n",
        "        #print(get_question(answer, context))\n",
        "        questions = keyword_to_sentences_map[word]\n",
        "        q = max(questions, key=len)\n",
        "\n",
        "        a = q.lower().find(answer)\n",
        "        b = a + len(answer)\n",
        "        q = q.replace(q[a:b], '_____')\n",
        "\n",
        "        results= model(q.replace('_____', '[MASK]'))\n",
        "        #print(results)\n",
        "\n",
        "        options = [result['token_str'] for result in results if isinstance(result, dict) and (answer not in result['token_str'].lower())]\n",
        "\n",
        "        if options:\n",
        "            print(q)\n",
        "            print(f'Ans: {answer}')\n",
        "            print(options)\n",
        "            print()\n",
        "\n",
        "\n",
        "get_questions(keyword_to_sentences_map, unmasker, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clOMqwG_9gAY",
        "outputId": "ef5cfab3-dbf0-4342-b0ab-183c46317ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This displaced the _____, deep-rooted grasses that trapped soil and moisture even during dry periods and high winds.\n",
            "Ans: native\n",
            "['dense', 'thick', 'tall', 'coarse', 'thin']\n",
            "\n",
            "The storms damaged the soil in around 100 million acres of land, leading to the greatest short-time migration in the American history, with approximately 3.5 million people _____ their farms and fields.\n",
            "Ans: abandoning\n",
            "['leaving', 'losing', 'fleeing', 'destroying']\n",
            "\n",
            "In fact, people welcome dust storms as they bring down temperatures and herald the arrival of the _____.\n",
            "Ans: monsoons\n",
            "['monsoon', 'sun', 'moon', 'rain', 'comet']\n",
            "\n",
            "But, the dust storms that have hit India since February this year have been quantitatively and qualitatively different from those in the _____.\n",
            "Ans: past\n",
            "['caribbean', 'himalayas', 'philippines', 'west']\n",
            "\n",
            "Else, we will see more _____ dust storms, and a choked Delhi would be a permanent feature.\n",
            "Ans: intense\n",
            "['frequent', 'severe', 'recent', 'permanent']\n",
            "\n",
            "Large-scale shelterbelt plantations, contour ploughing, conservation agriculture and establishment of conservation areas to keep millions of acres as grassland, helped halt _____ erosion and dust storms.\n",
            "Ans: wind\n",
            "['soil', 'coastal', 'crop', 'agricultural']\n",
            "\n",
            "Over the last 50 years, chemical- and water-intensive agriculture has _____ the traditional low-input agriculture.\n",
            "Ans: replaced\n",
            "['displaced', 'superseded', 'surpassed', 'eliminated']\n",
            "\n",
            "It is time India too recognizes its own Dust Bowl and initiates a large-scale ecological restoration programme to _____ it.\n",
            "Ans: halt\n",
            "['conserve', 'preserve', 'restore', 'protect', 'save']\n",
            "\n",
            "In most of these areas, the soil has been depleted and _____ levels have fallen precipitously.\n",
            "Ans: groundwater\n",
            "['water', 'nutrient', 'phosphorus', 'oxygen']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p src"
      ],
      "metadata": {
        "id": "5OHbdx1H2gPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/answerkey.py\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from keybert import KeyBERT\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "# we use nltk library to tokenize our text\n",
        "nltk.download('punkt')\n",
        "\n",
        "class AnswerKey:\n",
        "    \"\"\"\n",
        "    Generate answers using keyword extraction, and map them to sentences they appear in\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, text):\n",
        "        self.text = text\n",
        "\n",
        "        # KeyBert uses BERT-embeddings and simple cosine similarity to find the sub-phrases in a document that are the most similar to the document itself.\n",
        "        sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "        self.kw_model = KeyBERT(sentence_model)\n",
        "\n",
        "    def get_keywords(self, text):\n",
        "        \"\"\"\n",
        "        Given @input text, identify important keywords.\n",
        "        Here we use Sentence Transformer to extract keywords that best describe the text\n",
        "        \"\"\"\n",
        "        keywords_with_scores = self.kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), top_n=5, stop_words='english')\n",
        "        keywords = [kw[0] for kw in keywords_with_scores]\n",
        "        scores = [kw[1] for kw in keywords_with_scores]\n",
        "        return keywords\n",
        "\n",
        "    def tokenize_sentences(self, text):\n",
        "        \"\"\"\n",
        "        Given a @text input, returns tokenized sentences\n",
        "        \"\"\"\n",
        "        sentences = [sent_tokenize(text)]\n",
        "        sentences = [sentence for paragraph in sentences for sentence in paragraph]\n",
        "\n",
        "        # Remove sentences shorter than 20 letters.\n",
        "        sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "        return sentences\n",
        "\n",
        "    def get_sentences_for_keyword(self, kw_model, sentences, ngram_range=(1, 1), top_n=10):\n",
        "        \"\"\"\n",
        "        @kw_model: keyBERT model to extract keywords\n",
        "        @sentences: list of tokenized sentences\n",
        "        returns a map with keywords as keys mapped to the sentences they appear in.\n",
        "        \"\"\"\n",
        "        keyword_sentences = {}\n",
        "        for sentence in sentences:\n",
        "            keywords_found = [kw[0] for kw in kw_model.extract_keywords(sentence, keyphrase_ngram_range=ngram_range, top_n=top_n) if len(kw[0]) > 2]\n",
        "\n",
        "            for key in keywords_found:\n",
        "                keyword_sentences[key] = keyword_sentences.get(key, [])\n",
        "                keyword_sentences[key].append(sentence)\n",
        "\n",
        "        return keyword_sentences\n",
        "\n",
        "    def get_answers(self, ngram_range=(1, 2), top_n=10):\n",
        "        sentences = self.tokenize_sentences(self.text)\n",
        "        keyword_to_sentences = self.get_sentences_for_keyword(self.kw_model, sentences, ngram_range=ngram_range, top_n=top_n)\n",
        "        return keyword_to_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdoEWd_602lw",
        "outputId": "50c4f118-e556-43fc-d3e6-7583b0cf316e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/answerkey.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/t5model.py\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/mrm8488/t5-base-finetuned-question-generation-ap\"\n",
        "\n",
        "with open('../.env') as f:\n",
        "    API_TOKEN = str(f.read()).strip('\\n')\n",
        "    API_TOKEN = API_TOKEN.strip()\n",
        "\n",
        "headers = {\"Authorization\": f\"{API_TOKEN}\"}\n",
        "\n",
        "def query(payload):\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "    output =  json.loads(response.content.decode(\"utf-8\"))\n",
        "    return output\n",
        "\n",
        "# ping model to wake it up when this package is imported\n",
        "print(query(\"answer: Manuel context: Manuel has created RuPERTa-base with the support of HF-Transformers and Google\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xEru8l4t5zL",
        "outputId": "bde46097-fadd-45dd-f9f2-3ed1bef402cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/t5model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/model.py\n",
        "\n",
        "from transformers import pipeline\n",
        "from .t5model import query\n",
        "import random\n",
        "\n",
        "\n",
        "# load BERT model once\n",
        "unmasker = pipeline('fill-mask', model='distilbert-base-uncased')\n",
        "\n",
        "\n",
        "class Model:\n",
        "\n",
        "    def get_questions(self, keyword_to_sentences_map, model, k=5, declarative=True):\n",
        "        \"\"\"\"\n",
        "        Generates questions along with distractors\n",
        "        @input keyword_to_sentences_map : maps keywords to sentences they appear in\n",
        "        @model: BERT model that will be used to mask the keyword and generate distractors\n",
        "        @k (default 5), number of questions to return\n",
        "        \"\"\"\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # we can choose answer keys randomly from the pool of keywords\n",
        "        answer_keys = random.choices( list(keyword_to_sentences_map.keys()), k=k)\n",
        "\n",
        "        for answer in answer_keys:\n",
        "            sentences = keyword_to_sentences_map[answer]\n",
        "            sentence = max(sentences, key=len)\n",
        "\n",
        "            if len(sentence) < 20:\n",
        "                continue\n",
        "\n",
        "            start_idx = sentence.lower().find(answer)\n",
        "            end_idx = start_idx + len(answer)\n",
        "\n",
        "            # replace answer in sentence with blank line to form question\n",
        "            question = sentence.replace(sentence[start_idx: end_idx], '__________')\n",
        "\n",
        "            # generate distractors from BERT model\n",
        "            distractors = model(question.replace('__________', '[MASK]'))\n",
        "            options = [option['token_str'] for option in distractors if isinstance(option, dict) and (answer not in option['token_str'].lower())]\n",
        "            #print(distractors)\n",
        "\n",
        "            # generate question\n",
        "            if not declarative:\n",
        "                context = sentence\n",
        "                output = query(f\"answer: {answer} context: {context}\")\n",
        "                question_t5 = output[0][\"generated_text\"]\n",
        "\n",
        "                if options:\n",
        "                    results.append((question_t5, options, answer))\n",
        "            else:\n",
        "                if options:\n",
        "                    results.append((question, options, answer))\n",
        "\n",
        "        return results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZB4t9bK2X-o",
        "outputId": "9369ebb2-6b68-4dbb-e423-d6a12ed38e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "from src.answerkey import AnswerKey\n",
        "from src.model import Model, unmasker\n",
        "import streamlit as st\n",
        "\n",
        "PAGE_CONFIG = {\"page_title\":\"MCQ-App by Glad Nayak\",\"page_icon\":\":white_check_mark:\"}\n",
        "st.set_page_config(**PAGE_CONFIG)\n",
        "\n",
        "def render_input():\n",
        "    \"\"\"\n",
        "    Renders text area for input, and button\n",
        "    \"\"\"\n",
        "    # source of default text: https://www.fresherslive.com/online-test/reading-comprehension-test-questions-and-answers\n",
        "    text = \"\"\"The Dust Bowl, considered one of the greatest man-made ecological disasters, was a period of severe dust storms that lasted nearly a decade, starting 1931, and engulfed large parts of the US. The dust storms originated in the Great Plains-from states like Texas, Oklahoma, New Mexico, Colorado and Kansas. They were so severe that they choked everything and blocked out the sun for days. Sometimes, the storms travelled thousands of kilometres and blotted out monuments such as the Statue of Liberty. Citizens developed “dust pneumonia” and experienced chest pain and difficulty in breathing. The storms damaged the soil in around 100 million acres of land, leading to the greatest short-time migration in the American history, with approximately 3.5 million people abandoning their farms and fields.\n",
        "\n",
        "    Dust storms are an annual weather pattern in the northern region of India comprising Delhi, Haryana, Punjab, Uttar Pradesh and Rajasthan and Punjab, as also in the Sindh region of Pakistan. But, they are normally low in intensity and accompanied by rains. In fact, people welcome dust storms as they bring down temperatures and herald the arrival of the monsoons. But, the dust storms that have hit India since February this year have been quantitatively and qualitatively different from those in the past. They are high-powered storms travelling long distances and destroying properties and agricultural fields. Since February, they have affected as many as 16 states and killed more than 500 people. Cities like Delhi were choked in dust for days, with air quality level reaching the “severe” category on most days.\n",
        "\n",
        "    The Dust Bowl areas of the Great Plains are largely arid and semi-arid and prone to extended periods of drought. The US federal government encouraged settlement and development of large-scale agriculture by giving large parcels of grasslands to settlers. Waves of European settlers arrived at the beginning of the 20th century and converted grasslands into agricultural fields. At the same time, technological improvements allowed rapid mechanization of farm equipment, especially tractors and combined harvesters, which made it possible to operate larger parcels of land.\n",
        "\n",
        "    For the next two decades, agricultural land grew manifold and farmers undertook extensive deep ploughing of the topsoil with the help of tractors to plant crops like wheat. This displaced the native, deep-rooted grasses that trapped soil and moisture even during dry periods and high winds. Then, the drought struck. Successive waves of drought, which started in 1930 and ended in 1939, turned the Great Plains into bone-dry land. As the soil was already loose due to extensive ploughing, high winds turned them to dust and blew them away in huge clouds. Does this sound familiar? The dust storm regions of India and Pakistan too are largely arid and semi-arid. But they are at a lower altitude and hence less windy compared to the Great Plains. Over the last 50 years, chemical- and water-intensive agriculture has replaced the traditional low-input agriculture. Canal irrigation has been overtaken by the groundwater irrigation. In addition, mechanized agriculture has led to deeper ploughing, loosening more and more topsoil. The result has been devastating for the soil and groundwater. In most of these areas, the soil has been depleted and groundwater levels have fallen precipitously. On top of the man-made ecological destruction, the natural climatic cycle along with climate change is affecting the weather pattern of this region.\n",
        "\n",
        "    First, this area too is prone to prolonged drought. In fact, large parts of Haryana, Punjab, Delhi and western UP have experienced mildly dry to extremely dry conditions in the last six years. The Standardized Precipitation Index (SPI), which specifies the level of dryness or excess rains in an area, of large parts of Haryana, Punjab and Delhi has been negative since 2012. Rajasthan, on the other hand shows a positive SPI or excess rainfall. Second, this area is experiencing increasing temperatures. In fact, there seems to be a strong correlation between the dust storms and the rapid increase in temperature. Maximum temperatures across northern and western India have been far higher than normal since April this year. Last, climate change is affecting the pattern of Western Disturbances (WDs), leading to stronger winds and stronger storms. WDs are storms originating in the Mediterranean region that bring winter rain to northwestern India. But because of the warming of the Arctic and the Tibetan Plateau, indications are that the WDs are becoming unseasonal, frequent and stronger.\n",
        "\n",
        "    The Dust Bowl led the US government to initiate a large-scale land-management and soil-conservation programme. Large-scale shelterbelt plantations, contour ploughing, conservation agriculture and establishment of conservation areas to keep millions of acres as grassland, helped halt wind erosion and dust storms. It is time India too recognizes its own Dust Bowl and initiates a large-scale ecological restoration programme to halt it. Else, we will see more intense dust storms, and a choked Delhi would be a permanent feature.\n",
        "    \"\"\"\n",
        "    st.sidebar.subheader('Enter Text:')\n",
        "    text = st.sidebar.text_area('', text.strip(), height = 275)\n",
        "\n",
        "    ngram_range = st.sidebar.slider('answer ngram range:', value=[1, 2], min_value=1, max_value=3, step=1)\n",
        "    num_questions = st.sidebar.slider(\"number of questions:\", value=10, min_value=10, max_value=20, step=1)\n",
        "    question_type_str = st.sidebar.radio('question type:', ('declarative (fill in the blanks)', 'imperative'))\n",
        "    question_type = question_type_str == 'declarative (fill in the blanks)'\n",
        "\n",
        "    button = st.sidebar.button('Generate')\n",
        "\n",
        "    if button:\n",
        "        return (text, ngram_range, num_questions, question_type)\n",
        "\n",
        "def main():\n",
        "    # Render input text area\n",
        "    inputs = render_input()\n",
        "\n",
        "    if not inputs:\n",
        "        st.title('Generate Multiple Choice Questions(MCQs) from Text Automatically')\n",
        "        st.subheader('Enter Text, select how long a single answer should be(ngram_range), and number of questions to get started.')\n",
        "\n",
        "    else:\n",
        "        with st.spinner('Loading questions and distractors using BERT model'):\n",
        "            st.subheader(\"\")\n",
        "            st.title(\"\")\n",
        "            text, ngram_range, num_questions, question_type = inputs\n",
        "\n",
        "            # Load model\n",
        "            answerkeys = AnswerKey(text)\n",
        "            keyword_to_sentence = answerkeys.get_answers(ngram_range, num_questions)\n",
        "\n",
        "            model = Model()\n",
        "            quizzes = model.get_questions(keyword_to_sentence, unmasker, k=num_questions, declarative=question_type)\n",
        "\n",
        "            st.subheader('Questions')\n",
        "            for id, quiz in enumerate(quizzes):\n",
        "                question, options, answer = quiz\n",
        "                st.write(question)\n",
        "\n",
        "                for option in options[:3]:\n",
        "                    st.checkbox(option, key=id)\n",
        "\n",
        "                ans_button = st.checkbox(answer, key=id, value=True)\n",
        "\n",
        "            st.balloons()\n",
        "            st.button('Save')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L39detSG9EcG",
        "outputId": "6878432c-9260-4bf7-e372-0575083eccce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local Deployment"
      ],
      "metadata": {
        "id": "Awe9OfSjyEVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to test locally we install localtunnel\n",
        "!pip install streamlit > /dev/null\n",
        "!npm install -g localtunnel > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km5dinAgTGW9",
        "outputId": "1d0556ee-c6f1-45b4-94a7-8737fc7d0c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate requirements.txt and Install Requirements"
      ],
      "metadata": {
        "id": "-r__GQTbyNUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pipreqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdLDP419TNC2",
        "outputId": "9d16da39-2ff9-4957-b223-7a918b86e7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pipreqs\n",
            "  Downloading pipreqs-0.4.11-py2.py3-none-any.whl (32 kB)\n",
            "Collecting yarg\n",
            "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from pipreqs) (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from yarg->pipreqs) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (1.24.3)\n",
            "Installing collected packages: yarg, pipreqs\n",
            "Successfully installed pipreqs-0.4.11 yarg-0.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pipreqs ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geY6UpSbh8xQ",
        "outputId": "097c60e9-4db1-448a-8da0-0cf81f5b60c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Successfully saved requirements file in ./requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "7PRaACvciRsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "2ea0acec-3d50-45d8-e2e9-efe6866bd955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keybert==0.5.0\n",
            "  Downloading keybert-0.5.0.tar.gz (19 kB)\n",
            "Requirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (3.2.5)\n",
            "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (2.23.0)\n",
            "Collecting sentence_transformers==2.1.0\n",
            "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: streamlit==1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.4.0)\n",
            "Collecting transformers==4.15.0\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 10.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert==0.5.0->-r requirements.txt (line 1)) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert==0.5.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Collecting rich>=10.4.0\n",
            "  Downloading rich-11.0.0-py3-none-any.whl (215 kB)\n",
            "\u001b[K     |████████████████████████████████| 215 kB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.2.5->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->-r requirements.txt (line 3)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->-r requirements.txt (line 3)) (2.10)\n",
            "Collecting tokenizers>=0.10.3\n",
            "  Downloading tokenizers-0.11.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 41.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers==2.1.0->-r requirements.txt (line 4)) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers==2.1.0->-r requirements.txt (line 4)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers==2.1.0->-r requirements.txt (line 4)) (0.11.1+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers==2.1.0->-r requirements.txt (line 4)) (1.4.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 55.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (4.2.0)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (3.17.3)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (4.2.4)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (0.18.2)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (2.1.6)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (21.3)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (5.1.1)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (3.1.26)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (1.5.1)\n",
            "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (1.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (2.1.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (0.10.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (1.1.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (3.10.0.2)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (21.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit==1.4.0->-r requirements.txt (line 5)) (2.8.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0->-r requirements.txt (line 6)) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers>=0.10.3\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0->-r requirements.txt (line 6)) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.4.0->-r requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.4.0->-r requirements.txt (line 5)) (2.11.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.4.0->-r requirements.txt (line 5)) (0.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.4.0->-r requirements.txt (line 5)) (0.11.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit==1.4.0->-r requirements.txt (line 5)) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.4.0->-r requirements.txt (line 5)) (5.0.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.4.0->-r requirements.txt (line 5)) (0.18.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.4.0->-r requirements.txt (line 5)) (5.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=3.2.0->streamlit==1.4.0->-r requirements.txt (line 5)) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit==1.4.0->-r requirements.txt (line 5)) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit==1.4.0->-r requirements.txt (line 5)) (2018.9)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (7.6.5)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (5.1.1)\n",
            "Requirement already satisfied: ipykernel>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (6.7.0)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.1.3)\n",
            "Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (5.3.5)\n",
            "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (7.31.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (1.5.4)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (3.0.24)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.18.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (1.0.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (5.1.3)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (3.5.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit==1.4.0->-r requirements.txt (line 5)) (2.0.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (22.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (4.9.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.2.5)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert==0.5.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert==0.5.0->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (1.8.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (4.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.4.0->-r requirements.txt (line 5)) (0.5.1)\n",
            "Building wheels for collected packages: keybert, sentence-transformers\n",
            "  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keybert: filename=keybert-0.5.0-py3-none-any.whl size=20491 sha256=bbbe919859e4f837e5a7835c8a542338b3e6f971dafd986f1c9f9ad61e037a2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/1f/3f/590d2997adbb2d0e1f82e8ee05d42d6910e92c3ed283015ff8\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=120999 sha256=14af190582679f1822dd590c7d257c6af06fa2edc105fd36483ff93b94018141\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "Successfully built keybert sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, commonmark, colorama, sentence-transformers, rich, keybert\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed colorama-0.4.4 commonmark-0.9.1 huggingface-hub-0.4.0 keybert-0.5.0 pyyaml-6.0 rich-11.0.0 sacremoses-0.0.47 sentence-transformers-2.1.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run App"
      ],
      "metadata": {
        "id": "n_0d40f3yS3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.enableCORS=false &>/dev/null&\n",
        "\n",
        "!lt --Bypass-Tunnel-Reminder --subdomain 'myapp' --port 8501 &>/dev/null&"
      ],
      "metadata": {
        "id": "H3zMt4xXTJpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kill app and clean up memory\n",
        "st_id = !pgrep streamlit\n",
        "!kill {st_id[0]}\n",
        "\n",
        "lt_id = !pgrep lt\n",
        "!kill {lt_id[0]}"
      ],
      "metadata": {
        "id": "y1Ydu73OxiS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup CI/CD Pipeline"
      ],
      "metadata": {
        "id": "misTgFcMPSnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, for production deployment, we would first setup a CI/CD pipeline.\n",
        "\n",
        "1. first we, dockerize our app and push the code to container registry (Google's GCR) using Dockerfile and docker build.\n",
        "\n",
        "2. Automate deployment using Cloud Build such that everytime we push our code to Github our app gets deployed with latest changes.\n"
      ],
      "metadata": {
        "id": "IC-4sYdWVlPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Dockerfile\n",
        "#Base Image to use\n",
        "FROM python:3.7.9-slim\n",
        "\n",
        "#Expose port 8080\n",
        "EXPOSE 8080\n",
        "\n",
        "#Optional - install git to fetch packages directly from github\n",
        "RUN apt-get update && apt-get install -y git\n",
        "\n",
        "#Copy Requirements.txt file into app directory\n",
        "COPY requirements.txt app/requirements.txt\n",
        "COPY env app/.env\n",
        "\n",
        "#install all requirements in requirements.txt\n",
        "RUN pip install -r app/requirements.txt\n",
        "\n",
        "#Copy all files in current directory into app directory\n",
        "COPY . /app\n",
        "\n",
        "#Change Working Directory to app directory\n",
        "WORKDIR /app\n",
        "\n",
        "#Run the application on port 8080\n",
        "ENTRYPOINT [\"streamlit\", \"run\", \"app.py\", \"--server.port=8080\", \"--server.address=0.0.0.0\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvThHVQlycdZ",
        "outputId": "3d0e8ac2-bd83-44b6-b7ed-d43da4bec30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Dockerfile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cloudbuild.yaml\n",
        "\n",
        " steps:\n",
        " # Build the container image\n",
        " - name: 'gcr.io/cloud-builders/docker'\n",
        "   args: ['build', '-t', 'gcr.io/$PROJECT_ID/mcq-app:$COMMIT_SHA', '.']\n",
        " # Push the container image to Container Registry\n",
        " - name: 'gcr.io/cloud-builders/docker'\n",
        "   args: ['push', 'gcr.io/$PROJECT_ID/mcq-app:$COMMIT_SHA']\n",
        " # Deploy container image to Cloud Run\n",
        " - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'\n",
        "   entrypoint: gcloud\n",
        "   args:\n",
        "   - 'run'\n",
        "   - 'deploy'\n",
        "   - 'mcq-app'\n",
        "   - '--image'\n",
        "   - 'gcr.io/$PROJECT_ID/mcq-app:$COMMIT_SHA'\n",
        "   - '--region'\n",
        "   - 'us-central1'\n",
        " images:\n",
        " - 'gcr.io/$PROJECT_ID/mcq-app:$COMMIT_SHA'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBwHUQ2-WXB8",
        "outputId": "a8007bc2-5ca3-4a72-b1e1-140e94e0e338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cloudbuild.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# setup Google Cloud project\n",
        "\n",
        "PROJECT_ID = 'mcq-from-text'\n",
        "!gcloud config set project {PROJECT_ID}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fyb1_9HjPYHa",
        "outputId": "8a8484f0-eca4-4feb-c30c-e6f3fa0c4d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now, we package our code as docker image using Dockerfile and push it to Google's Container Registry\n",
        "\n",
        "# 1. build image locally and test run at localhost\n",
        "!docker build  --timeout 20m --tag gcr.io/{PROJECT_ID}/mcq-app:latest .\n",
        "\n",
        "# 2. build using gcloud\n",
        "!docker build  --timeout 20m --tag gcr.io/{PROJECT_ID}/mcq-app:latest .\n",
        "\n",
        "# 3. submit to Google's Container registry\n",
        "!gcloud builds submit --timeout 30m  --tag gcr.io/${PROJECT_ID}/mcq-app:latest\n",
        "\n",
        "# 4. automate CI/CD pipeline\n",
        "!gcloud builds submit --config cloudbuild.yaml ."
      ],
      "metadata": {
        "id": "gnwtM-b6S4--"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}